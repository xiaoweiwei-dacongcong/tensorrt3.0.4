

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>tensorrt.infer &mdash; TensorRT 3.0.2 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato" type="text/css" />
  
    <link rel="stylesheet" href="../_static/css/tensorrt_theme.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="TensorRT 3.0.2 documentation" href="../index.html"/>
        <link rel="next" title="tensorrt.utils" href="utils.html"/>
        <link rel="prev" title="Manually Construct a TensorRT Engine" href="../workflows/manually_construct_tensorrt_engine.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> TensorRT
          

          
            
            <img src="../_static/nvlogo.svg" class="logo" />
          
          </a>

          
            
            
              <div class="version">
                3.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Using the UFF Toolkit:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../uff/uff.html">uff</a></li>
</ul>
<p class="caption"><span class="caption-text">Workflows</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../workflows/caffe_to_tensorrt.html">Using TensorRT to Optimize Caffe Models in Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../workflows/tf_to_tensorrt.html">Generate TensorRT Engines from Tensorflow (or other UFF Compatable Frameworks)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../workflows/manually_construct_tensorrt_engine.html">Manually Construct a TensorRT Engine</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">tensorrt.infer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#foundational-types">Foundational Types</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#datatype">DataType</a></li>
<li class="toctree-l3"><a class="reference internal" href="#weights">Weights</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dims">Dims</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dimshw">DimsHW</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dimschw">DimsCHW</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dimsnchw">DimsNCHW</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dimensiontype">DimensionType</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#engine-and-inference">Engine and Inference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#builder">Builder</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-infer-builder">create_infer_builder</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cudaengine">CudaEngine</a></li>
<li class="toctree-l3"><a class="reference internal" href="#executioncontext">ExecutionContext</a></li>
<li class="toctree-l3"><a class="reference internal" href="#runtime">Runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-infer-runtime">create_infer_runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hostmemory">HostMemory</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#graph-definition">Graph Definition</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#networkdefinition">NetworkDefinition</a></li>
<li class="toctree-l3"><a class="reference internal" href="#layertype">LayerType</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tensor">Tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="#layer">Layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#convolutionlayer">ConvolutionLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fullyconnectedlayer">FullyConnectedLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activationlayer">ActivationLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activationtype">ActivationType</a></li>
<li class="toctree-l3"><a class="reference internal" href="#poolinglayer">PoolingLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#poolingtype">PoolingType</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lrnlayer">LRNLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scalelayer">ScaleLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scalemode">ScaleMode</a></li>
<li class="toctree-l3"><a class="reference internal" href="#softmaxlayer">SoftmaxLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concatenationlayer">ConcatenationLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deconvolutionlayer">DeconvolutionLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#elementwiselayer">ElementWiseLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#elementwiseoperation">ElementWiseOperation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#shufflelayer">ShuffleLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#permutation">Permutation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#unarylayer">UnaryLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#unaryoperation">UnaryOperation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pluginlayer">PluginLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#paddinglayer">PaddingLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rnnlayer">RNNLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rnnoperation">RNNOperation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rnndirection">RNNDirection</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rnninputmode">RNNInputMode</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ioutputdimensionsformula">IOutputDimensionsFormula</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#int8-calibration">Int8 Calibration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#int8calibrator">Int8Calibrator</a></li>
<li class="toctree-l3"><a class="reference internal" href="#int8entropycalibrator">Int8EntropyCalibrator</a></li>
<li class="toctree-l3"><a class="reference internal" href="#int8legacycalibrator">Int8LegacyCalibrator</a></li>
<li class="toctree-l3"><a class="reference internal" href="#calibrationalgotype">CalibrationAlgoType</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#logger">Logger</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Logger</a></li>
<li class="toctree-l3"><a class="reference internal" href="#consolelogger">ConsoleLogger</a></li>
<li class="toctree-l3"><a class="reference internal" href="#logseverity">LogSeverity</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#profiler">Profiler</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id2">Profiler</a></li>
<li class="toctree-l3"><a class="reference internal" href="#consoleprofiler">ConsoleProfiler</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">tensorrt.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="lite.html">tensorrt.lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="parsers.html">tensorrt.parsers</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">TensorRT</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>tensorrt.infer</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/pkg_ref/infer.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

/* nice headers on first paragraph of info/warning boxes */
.admonition .first {
    margin: -12px;
    padding: 6px 12px;
    margin-bottom: 12px;
    color: #fff;
    line-height: 1;
    display: block;
}
.admonition.warning .first {
    background: #f0b37e;
}
.admonition.note .first {
    background: #6ab0de;
}
.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}
</style>
<div class="section" id="tensorrt-infer">
<h1>tensorrt.infer<a class="headerlink" href="#tensorrt-infer" title="Permalink to this headline">¶</a></h1>
<p>The <code class="xref py py-mod docutils literal"><span class="pre">infer</span></code> package contains an interface for libnvinfer. This module is used for graph definition,
engine building and inference execution.</p>
<span class="target" id="module-tensorrt.infer"></span><p>Bindings for libnvinfer</p>
<div class="section" id="foundational-types">
<h2>Foundational Types<a class="headerlink" href="#foundational-types" title="Permalink to this headline">¶</a></h2>
<div class="section" id="datatype">
<h3>DataType<a class="headerlink" href="#datatype" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.DataType">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">DataType</code><a class="reference internal" href="../_modules/tensorrt/infer/_infer_enums.html#DataType"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorrt.infer.DataType" title="Permalink to this definition">¶</a></dt>
<dd><p>Available data types</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
<dl class="attribute">
<dt id="tensorrt.infer.DataType.input_type">
<code class="descname">input_type</code><a class="headerlink" href="#tensorrt.infer.DataType.input_type" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Returns</em> –</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">numpy</span> <span class="pre">type</span></code>: expected data type for input</li>
</ul>
</dd></dl>

<dl class="attribute">
<dt id="tensorrt.infer.DataType.nptype">
<code class="descname">nptype</code><a class="headerlink" href="#tensorrt.infer.DataType.nptype" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Returns</em> –</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">numpy</span> <span class="pre">type</span></code>: Analogous numpy type</li>
</ul>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DataType.size">
<code class="descname">size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorrt/infer/_infer_enums.html#DataType.size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorrt.infer.DataType.size" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns:
- <code class="docutils literal"><span class="pre">int</span></code>: Size in bytes</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="weights">
<h3>Weights<a class="headerlink" href="#weights" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Weights">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Weights</code><a class="headerlink" href="#tensorrt.infer.Weights" title="Permalink to this definition">¶</a></dt>
<dd><p>an array of weights used as a layer parameter</p>
<p>The weights are held by reference until the engine has been built. Therefore the data referenced by <cite>values</cite> field should be preserved until the build is complete</p>
<dl class="attribute">
<dt>
<code class="descname">* `type`</code></dt>
<dd><p><cite>DataType</cite> – the type of the weights</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">* `values`</code></dt>
<dd><p><cite>const void *</cite> – the weight values, in a contiguous array</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">* `count`</code></dt>
<dd><p><cite>int64_t</cite> – the number of weights in the array</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">C++ includes</code></dt>
<dd><p><em>NvInfer.h</em></p>
</dd></dl>

<dl class="attribute">
<dt id="tensorrt.infer.Weights.count">
<code class="descname">count</code><a class="headerlink" href="#tensorrt.infer.Weights.count" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="tensorrt.infer.Weights.type">
<code class="descname">type</code><a class="headerlink" href="#tensorrt.infer.Weights.type" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="tensorrt.infer.Weights.values">
<code class="descname">values</code><a class="headerlink" href="#tensorrt.infer.Weights.values" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="dims">
<h3>Dims<a class="headerlink" href="#dims" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Dims">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Dims</code><a class="headerlink" href="#tensorrt.infer.Dims" title="Permalink to this definition">¶</a></dt>
<dd><p>structure to define the dimensions of a tensor</p>
<p>note: : currently the following formats are supported for layer inputs and outputs:</p>
<blockquote>
<div><ul class="simple">
<li>zero or more index dimensions followed by one channel and two spatial dimensions (e.g. CHW)</li>
<li>one time series dimension followed by one index dimension followed by one channel dimension (i.e. TNC)</li>
</ul>
</div></blockquote>
<dl class="attribute">
<dt>
<code class="descname">* `MAX_DIMS`</code></dt>
<dd><p><cite>const int</cite> – the maximum number of dimensions supported for a tensor</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">* `nbDims`</code></dt>
<dd><p><cite>int</cite> – the number of dimensions</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">* `d`</code></dt>
<dd><p><cite>int</cite> – the extent of each dimension</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">* `type`</code></dt>
<dd><p><cite>DimensionType</cite> – the type of each dimension</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">C++ includes</code></dt>
<dd><p><em>NvInfer.h</em></p>
</dd></dl>

<dl class="attribute">
<dt id="tensorrt.infer.Dims.d">
<code class="descname">d</code><a class="headerlink" href="#tensorrt.infer.Dims.d" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="tensorrt.infer.Dims.nbDims">
<code class="descname">nbDims</code><a class="headerlink" href="#tensorrt.infer.Dims.nbDims" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="tensorrt.infer.Dims.type">
<code class="descname">type</code><a class="headerlink" href="#tensorrt.infer.Dims.type" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="dimshw">
<h3>DimsHW<a class="headerlink" href="#dimshw" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.DimsHW">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">DimsHW</code><a class="headerlink" href="#tensorrt.infer.DimsHW" title="Permalink to this definition">¶</a></dt>
<dd><p>descriptor for two-dimensional spatial data</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.DimsHW.h">
<code class="descname">h</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DimsHW.h" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">h()</span> <span class="pre">const</span>&#160; <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the height</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">the height</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DimsHW.w">
<code class="descname">w</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DimsHW.w" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">w()</span> <span class="pre">const</span>&#160; <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the width</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">the width</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="dimschw">
<h3>DimsCHW<a class="headerlink" href="#dimschw" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.DimsCHW">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">DimsCHW</code><a class="headerlink" href="#tensorrt.infer.DimsCHW" title="Permalink to this definition">¶</a></dt>
<dd><p>descriptor for data with one channel dimension and two spatial dimensions</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.DimsCHW.c">
<code class="descname">c</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DimsCHW.c" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">c()</span> <span class="pre">const</span>&#160; <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the channel count</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">the channel count</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DimsCHW.h">
<code class="descname">h</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DimsCHW.h" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">h()</span> <span class="pre">const</span>&#160; <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the height</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">the height</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DimsCHW.w">
<code class="descname">w</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DimsCHW.w" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">w()</span> <span class="pre">const</span>&#160; <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the width</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">the width</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="dimsnchw">
<h3>DimsNCHW<a class="headerlink" href="#dimsnchw" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.DimsNCHW">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">DimsNCHW</code><a class="headerlink" href="#tensorrt.infer.DimsNCHW" title="Permalink to this definition">¶</a></dt>
<dd><p>descriptor for data with one index dimension, one channel dimension and two spatial dimensions</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.DimsNCHW.c">
<code class="descname">c</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DimsNCHW.c" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">c()</span> <span class="pre">const</span>&#160; <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the channel count</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">the channel count</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DimsNCHW.h">
<code class="descname">h</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DimsNCHW.h" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">h()</span> <span class="pre">const</span>&#160; <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the height</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">the height</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DimsNCHW.n">
<code class="descname">n</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DimsNCHW.n" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">n()</span> <span class="pre">const</span>&#160; <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the index count</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">the index count</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DimsNCHW.w">
<code class="descname">w</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DimsNCHW.w" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">w()</span> <span class="pre">const</span>&#160; <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the width</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">the width</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="dimensiontype">
<h3>DimensionType<a class="headerlink" href="#dimensiontype" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.DimensionType">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">DimensionType</code><a class="reference internal" href="../_modules/tensorrt/infer/_infer_enums.html#DimensionType"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorrt.infer.DimensionType" title="Permalink to this definition">¶</a></dt>
<dd><p>Available dimension types</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
</div>
<div class="section" id="engine-and-inference">
<h2>Engine and Inference<a class="headerlink" href="#engine-and-inference" title="Permalink to this headline">¶</a></h2>
<div class="section" id="builder">
<h3>Builder<a class="headerlink" href="#builder" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Builder">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Builder</code><a class="headerlink" href="#tensorrt.infer.Builder" title="Permalink to this definition">¶</a></dt>
<dd><p>builds an engine from a network definition</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.Builder.build_cuda_engine">
<code class="descname">build_cuda_engine</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.build_cuda_engine" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">buildCudaEngine(nvinfer1::INetworkDefinition</span> <span class="pre">&amp;network)=0</span> <span class="pre">-&gt;</span> <span class="pre">nvinfer1::ICudaEngine</span> <span class="pre">*</span></code></p>
<p>build a CUDA engine from a network definition</p>
<p>See also: INetworkDefinition ICudaEngine</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.create_network">
<code class="descname">create_network</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.create_network" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">createNetwork()=0</span> <span class="pre">-&gt;</span> <span class="pre">nvinfer1::INetworkDefinition</span> <span class="pre">*</span></code></p>
<p>create a network definition object.</p>
<p>See also: INetworkDefinition</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.destroy">
<code class="descname">destroy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.destroy" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">destroy()=0</span></code></p>
<p>destroy this object</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.get_average_find_iterations">
<code class="descname">get_average_find_iterations</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.get_average_find_iterations" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getAverageFindIterations()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>query the number of averaging iterations</p>
<p>See also: setMinFindIterations()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.get_debug_sync">
<code class="descname">get_debug_sync</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.get_debug_sync" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getDebugSync()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>query whether the builder will use debug synchronization</p>
<p>See also: setDebugSync()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.get_half2_mode">
<code class="descname">get_half2_mode</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.get_half2_mode" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getHalf2Mode()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>query whether half2 mode is used</p>
<p>See also: setHalf2Mode()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.get_int8_mode">
<code class="descname">get_int8_mode</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.get_int8_mode" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getInt8Mode()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>query whether Int8 mode is used</p>
<p>See also: setInt8Mode()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.get_max_batch_size">
<code class="descname">get_max_batch_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.get_max_batch_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getMaxBatchSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the maximum batch size</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the maximum batch size</em></li>
<li><strong>See also</strong> (<em>setMaxBatchSize()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.get_max_workspace_size">
<code class="descname">get_max_workspace_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.get_max_workspace_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getMaxWorkspaceSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">std::size_t</span></code></p>
<p>get the maximum workspace size</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the maximum workspace size</em></li>
<li><strong>See also</strong> (<em>setMaxWorkspaceSize()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.get_min_find_iterations">
<code class="descname">get_min_find_iterations</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.get_min_find_iterations" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getMinFindIterations()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>query the number of minimzation iterations</p>
<p>See also: setMinFindIterations()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.platform_has_fast_fp16">
<code class="descname">platform_has_fast_fp16</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.platform_has_fast_fp16" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">platformHasFastFp16()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>determine whether the platform has fast native fp16</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.platform_has_fast_int8">
<code class="descname">platform_has_fast_int8</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.platform_has_fast_int8" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">platformHasFastInt8()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>determine whether the platform has fast native int8</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.set_average_find_iterations">
<code class="descname">set_average_find_iterations</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.set_average_find_iterations" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setAverageFindIterations(int</span> <span class="pre">avgFind)=0</span></code></p>
<p>set the number of minimization iterations used when timing layers</p>
<p>When timing layers, the builder minimizes over a set of average times for layer execution. This parameter controls the number of iterations used in averaging.</p>
<p>See also: getAverageFindIterations()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.set_debug_sync">
<code class="descname">set_debug_sync</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.set_debug_sync" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setDebugSync(bool</span> <span class="pre">sync)=0</span></code></p>
<p>set whether the builder should use debug synchronization</p>
<p>if this flag is true, the builder will synchronize after timing each layer, and report the layer name. It can be useful when diagnosing issues at build time.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.set_half2_mode">
<code class="descname">set_half2_mode</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.set_half2_mode" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setHalf2Mode(bool</span> <span class="pre">mode)=0</span></code></p>
<p>set whether half2 mode is used</p>
<p>half2 mode is a paired-image mode that is significantly faster for batch sizes greater than one on platforms with fp16 support</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>mode</strong> (<em>*</em>) – whether half2 mode is used</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.set_int8_calibrator">
<code class="descname">set_int8_calibrator</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.set_int8_calibrator" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setInt8Calibrator(IInt8Calibrator</span> <span class="pre">*calibrator)=0</span></code></p>
<p>set Int8 Calibration interface</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.set_int8_mode">
<code class="descname">set_int8_mode</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.set_int8_mode" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setInt8Mode(bool</span> <span class="pre">mode)=0</span></code></p>
<p>set the maximum value for a region</p>
<p>used for INT8 mode compression</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.set_max_batch_size">
<code class="descname">set_max_batch_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.set_max_batch_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setMaxBatchSize(int</span> <span class="pre">batchSize)=0</span></code></p>
<p>set the maximum batch size</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>batchSize</strong> (<em>*</em>) – the maximum batch size which can be used at execution time, and also the batch size for which the engine will be optimized</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.set_max_workspace_size">
<code class="descname">set_max_workspace_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.set_max_workspace_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setMaxWorkspaceSize(std::size_t</span> <span class="pre">workspaceSize)=0</span></code></p>
<p>set the maximum workspace size</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>workspaceSize</strong> (<em>*</em>) – the maximum GPU temporary memory which the engine can use at execution time</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Builder.set_min_find_iterations">
<code class="descname">set_min_find_iterations</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Builder.set_min_find_iterations" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setMinFindIterations(int</span> <span class="pre">minFind)=0</span></code></p>
<p>set the number of minimization iterations used when timing layers</p>
<p>When timing layers, the builder minimizes over a set of average times for layer execution. This parameter controls the number of iterations used in minimzation.</p>
<p>See also: getMinFindIterations()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="create-infer-builder">
<h3>create_infer_builder<a class="headerlink" href="#create-infer-builder" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="tensorrt.infer.create_infer_builder">
<code class="descclassname">tensorrt.infer.</code><code class="descname">create_infer_builder</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.create_infer_builder" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="cudaengine">
<h3>CudaEngine<a class="headerlink" href="#cudaengine" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.CudaEngine">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">CudaEngine</code><a class="headerlink" href="#tensorrt.infer.CudaEngine" title="Permalink to this definition">¶</a></dt>
<dd><p>an engine for executing inference on a built network</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.CudaEngine.binding_is_input">
<code class="descname">binding_is_input</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.binding_is_input" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">bindingIsInput(int</span> <span class="pre">bindingIndex)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>determine whether a binding is an input binding</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>bindingIndex</strong> (<em>*</em>) – the binding index</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>true if the index corresponds to an input binding and the index is in range</em></li>
<li><strong>See also</strong> (<em>getBindingIndex()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.create_execution_context">
<code class="descname">create_execution_context</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.create_execution_context" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">createExecutionContext()=0</span> <span class="pre">-&gt;</span> <span class="pre">IExecutionContext</span> <span class="pre">*</span></code></p>
<p>create an execution context</p>
<p>See also: IExecutionContext.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.destroy">
<code class="descname">destroy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.destroy" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">destroy()=0</span></code></p>
<p>destroy this object</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.get_binding_data_type">
<code class="descname">get_binding_data_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.get_binding_data_type" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getBindingDataType(int</span> <span class="pre">bindingIndex)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DataType</span></code></p>
<p>determine the required data type for a buffer from its binding index</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>bindingIndex</strong> (<em>*</em>) – the binding index</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the type of the data in the buffer</em></li>
<li><strong>See also</strong> (<em>getBindingIndex()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.get_binding_dimensions">
<code class="descname">get_binding_dimensions</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.get_binding_dimensions" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getBindingDimensions(int</span> <span class="pre">bindingIndex)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Dims</span></code></p>
<p>get the dimensions of a binding</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>bindingIndex</strong> (<em>*</em>) – the binding index</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the dimensions of the binding if the index is in range, otherwise (0,0,0)</em></li>
<li><strong>See also</strong> (<em>getBindingIndex()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.get_binding_index">
<code class="descname">get_binding_index</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.get_binding_index" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getBindingIndex(const</span> <span class="pre">char</span> <span class="pre">*name)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>retrieve the binding index for a named tensor</p>
<p>IExecutionContext::enqueue() and IExecutionContext::execute() require an array of buffers.</p>
<p>Engine bindings map from tensor names to indices in this array. Binding indices are assigned at engine build time, and take values in the range [0 … n-1] where n is the total number of inputs and
outputs.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>name</strong> (<em>*</em>) – the tensor name</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the binding index for the named tensor, or -1 if the name is not found</em></li>
<li><em>see getNbBindings() getBindingIndex()</em></li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.get_binding_name">
<code class="descname">get_binding_name</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.get_binding_name" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getBindingName(int</span> <span class="pre">bindingIndex)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">const</span> <span class="pre">char</span> <span class="pre">*</span></code></p>
<p>retrieve the name corresponding to a binding index</p>
<p>this is the reverse mapping to that provided by getBindingIndex()</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>bindingIndex</strong> (<em>*</em>) – the binding index</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the name corresponding to the index, or nullptr if the index is out of range</em></li>
<li><strong>See also</strong> (<em>getBindingIndex()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.get_max_batch_size">
<code class="descname">get_max_batch_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.get_max_batch_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getMaxBatchSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the maximum batch size which can be used for inference</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the maximum batch size for this engine</em></li>
<li><strong>See also</strong> (<em>getBindingIndex()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.get_nb_bindings">
<code class="descname">get_nb_bindings</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.get_nb_bindings" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getNbBindings()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the number of binding indices</p>
<p>See also: getBindingIndex();</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.get_nb_layers">
<code class="descname">get_nb_layers</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.get_nb_layers" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getNbLayers()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the number of layers in the network</p>
<p>the number of layers in the network is not necessarily the number in the original network definition, as layers may be combined or eliminated as the engine is optimized. This value can be useful when
building per-layer tables, such as when aggregating profiling data over a number of executions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">the number of layers in the network</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.get_workspace_size">
<code class="descname">get_workspace_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.get_workspace_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getWorkspaceSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">std::size_t</span></code></p>
<p>get the amount of workspace the engine uses.</p>
<p>the workspace size will be no greater than the value provided to the builder when the engine was built, and will typically be smaller. Workspace will be allocated for each execution context.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.CudaEngine.serialize">
<code class="descname">serialize</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.CudaEngine.serialize" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">serialize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">IHostMemory</span> <span class="pre">*</span></code></p>
<p>serialize the network to a stream</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>A IHostMemory object that contains the serialized engine.</em></li>
<li><em>the network may be deserialized with IRuntime::deserializeCudaEngine()</em></li>
<li><strong>See also</strong> (<em>IRuntime::deserializeCudaEngine()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="executioncontext">
<h3>ExecutionContext<a class="headerlink" href="#executioncontext" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ExecutionContext">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ExecutionContext</code><a class="headerlink" href="#tensorrt.infer.ExecutionContext" title="Permalink to this definition">¶</a></dt>
<dd><p>context for executing inference using an engine</p>
<p>Multiple execution contexts may exist for one ICudaEngine instance, allowing the same engine to be used for the execution of multiple batches simultaneously.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.ExecutionContext.destroy">
<code class="descname">destroy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ExecutionContext.destroy" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">destroy()=0</span></code></p>
<p>destroy this object</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ExecutionContext.enqueue">
<code class="descname">enqueue</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ExecutionContext.enqueue" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">enqueue(int</span> <span class="pre">batchSize,</span> <span class="pre">void</span> <span class="pre">**bindings,</span> <span class="pre">cudaStream_t</span> <span class="pre">stream,</span> <span class="pre">cudaEvent_t</span> <span class="pre">*inputConsumed)=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>asynchronously execute inference on a batch</p>
<p>this method requires a array of input and output buffers. The mapping from tensor names to indices can be queried using ICudaEngine::getBindingIndex()</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>batchSize</strong> (<em>*</em>) – the batch size. This is at most the value supplied when the engine was built.</li>
<li><strong>bindings</strong> (<em>*</em>) – an array of pointers to input and output buffers for the network.</li>
<li><strong>stream</strong> (<em>*</em>) – a cuda stream on which the inference kernels will be enqueued</li>
<li><strong>inputConsumed</strong> (<em>*</em>) – an optional event which will be signaled when the input buffers can be refilled with new data</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>true if the kernels were enqueued successfully</em></li>
<li><strong>See also</strong> (<em>ICudaEngine::getBindingIndex() ICudaEngine::getMaxBatchSize()</em>)</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ExecutionContext.execute">
<code class="descname">execute</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ExecutionContext.execute" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">execute(int</span> <span class="pre">batchSize,</span> <span class="pre">void</span> <span class="pre">**bindings)=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>synchronously execute inference on a batch</p>
<p>this method requires a array of input and output buffers. The mapping from tensor names to indices can be queried using ICudaEngine::getBindingIndex()</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>batchSize</strong> (<em>*</em>) – the batch size. This is at most the value supplied when the engine was built.</li>
<li><strong>bindings</strong> (<em>*</em>) – an array of pointers to input and output buffers for the network.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>true if execution succeeded</em></li>
<li><strong>See also</strong> (<em>ICudaEngine::getBindingIndex() ICudaEngine::getMaxBatchSize()</em>)</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ExecutionContext.get_debug_sync">
<code class="descname">get_debug_sync</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ExecutionContext.get_debug_sync" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getDebugSync()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>get the debug sync flag</p>
<p>See also: setDebugSync()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ExecutionContext.get_engine">
<code class="descname">get_engine</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ExecutionContext.get_engine" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getEngine()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">const</span> <span class="pre">ICudaEngine</span> <span class="pre">&amp;</span></code></p>
<p>get the associated engine</p>
<p>See also: ICudaEngine</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ExecutionContext.get_profiler">
<code class="descname">get_profiler</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ExecutionContext.get_profiler" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getProfiler()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">IProfiler</span> <span class="pre">*</span></code></p>
<p>get the profiler</p>
<p>See also: IProfiler setProfiler()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ExecutionContext.set_debug_sync">
<code class="descname">set_debug_sync</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ExecutionContext.set_debug_sync" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setDebugSync(bool</span> <span class="pre">sync)=0</span></code></p>
<p>set the debug sync flag</p>
<p>if this flag is set to true, the engine will log the successful execution for each kernel during execute(). It has no effect when using enqueue().</p>
<p>See also: getDebugSync()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ExecutionContext.set_profiler">
<code class="descname">set_profiler</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ExecutionContext.set_profiler" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setProfiler(IProfiler</span> <span class="pre">*)=0</span></code></p>
<p>set the profiler</p>
<p>See also: IProfiler getProfiler()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="runtime">
<h3>Runtime<a class="headerlink" href="#runtime" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Runtime">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Runtime</code><a class="headerlink" href="#tensorrt.infer.Runtime" title="Permalink to this definition">¶</a></dt>
<dd><p>allows a serialized engine to be deserialized</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.Runtime.deserialize_cuda_engine">
<code class="descname">deserialize_cuda_engine</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Runtime.deserialize_cuda_engine" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">deserializeCudaEngine(const</span> <span class="pre">void</span> <span class="pre">*blob,</span> <span class="pre">std::size_t</span> <span class="pre">size,</span> <span class="pre">IPluginFactory</span> <span class="pre">*pluginFactory)=0</span> <span class="pre">-&gt;</span> <span class="pre">nvinfer1::ICudaEngine</span> <span class="pre">*</span></code></p>
<p>deserialize an engine from a stream</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>blob</strong> (<em>*</em>) – the memory that holds the serialized engine.</li>
<li><strong>size</strong> (<em>*</em>) – the size of the memory</li>
<li><strong>pluginFactory</strong> (<em>*</em>) – the plugin factory, if any plugins are used by the network, otherwise nullptr</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the engine, or nullptr if it could not be deserialized</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Runtime.destroy">
<code class="descname">destroy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Runtime.destroy" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">destroy()=0</span></code></p>
<p>destroy this object</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="create-infer-runtime">
<h3>create_infer_runtime<a class="headerlink" href="#create-infer-runtime" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="tensorrt.infer.create_infer_runtime">
<code class="descclassname">tensorrt.infer.</code><code class="descname">create_infer_runtime</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.create_infer_runtime" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="hostmemory">
<h3>HostMemory<a class="headerlink" href="#hostmemory" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.HostMemory">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">HostMemory</code><a class="headerlink" href="#tensorrt.infer.HostMemory" title="Permalink to this definition">¶</a></dt>
<dd><p>class to handle library allocated memory that is accessible to the user.</p>
<p>The memory allocated via the host memory object is owned by the library and will be de-allocated when the destroy method is called.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.HostMemory.data">
<code class="descname">data</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.HostMemory.data" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">data()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">void</span> <span class="pre">*</span></code></p>
<p>A pointer to the raw data that is owned by the library.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.HostMemory.destroy">
<code class="descname">destroy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.HostMemory.destroy" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">destroy()=0</span></code></p>
<p>Destroy the allocated memory.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.HostMemory.size">
<code class="descname">size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.HostMemory.size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">size()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">std::size_t</span></code></p>
<p>The size in bytes of the data that was allocated.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.HostMemory.type">
<code class="descname">type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.HostMemory.type" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">type()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DataType</span></code></p>
<p>The type of the memory that was allocated.</p>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="graph-definition">
<h2>Graph Definition<a class="headerlink" href="#graph-definition" title="Permalink to this headline">¶</a></h2>
<div class="section" id="networkdefinition">
<h3>NetworkDefinition<a class="headerlink" href="#networkdefinition" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.NetworkDefinition">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">NetworkDefinition</code><a class="headerlink" href="#tensorrt.infer.NetworkDefinition" title="Permalink to this definition">¶</a></dt>
<dd><p>a network definition for input to the builder</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_activation">
<code class="descname">add_activation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_activation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">addActivation(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">ActivationType</span> <span class="pre">type)=0</span> <span class="pre">-&gt;</span> <span class="pre">IActivationLayer</span> <span class="pre">*</span></code></p>
<p>add an activation layer to the network</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>*</em>) – the input tensor to the layer</li>
<li><strong>type</strong> (<em>*</em>) – the type of activation function to apply</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the new convolution layer, or null if it could not be created</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_concatenation">
<code class="descname">add_concatenation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_concatenation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">addConcatenation(ITensor</span> <span class="pre">*const</span> <span class="pre">*inputs,</span> <span class="pre">int</span> <span class="pre">nbInputs)=0</span> <span class="pre">-&gt;</span> <span class="pre">IConcatenationLayer</span> <span class="pre">*</span></code></p>
<p>add a concatenation layer to the network</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inputs</strong> (<em>*</em>) – the input tensors to the layer</li>
<li><strong>nbInputs</strong> (<em>*</em>) – the number of input tensors</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>the new concatenation layer, or null if it could not be created</em></li>
<li><strong>**Warning**</strong> (<em>All tensors must have the same dimensions for all dimensions except for channel.</em>)</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_convolution">
<code class="descname">add_convolution</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_convolution" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">addConvolution(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">int</span> <span class="pre">nbOutputMaps,</span> <span class="pre">DimsHW</span> <span class="pre">kernelSize,</span> <span class="pre">Weights</span> <span class="pre">kernelWeights,</span> <span class="pre">Weights</span> <span class="pre">biasWeights)=0</span> <span class="pre">-&gt;</span> <span class="pre">IConvolutionLayer</span> <span class="pre">*</span></code></p>
<p>add a convolution layer to the network</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>*</em>) – the input tensor to the convolution</li>
<li><strong>nbOutputMaps</strong> (<em>*</em>) – the number of output feature maps for the convolution</li>
<li><strong>kernelSize</strong> (<em>*</em>) – the HW-dimensions of the convolution kernel</li>
<li><strong>kernelWeights</strong> (<em>*</em>) – the kernel weights for the convolution</li>
<li><strong>biasWeights</strong> (<em>*</em>) – the optional bias weights for the convolution</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the new convolution layer, or null if it could not be created</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_deconvolution">
<code class="descname">add_deconvolution</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_deconvolution" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">addDeconvolution(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">int</span> <span class="pre">nbOutputMaps,</span> <span class="pre">DimsHW</span> <span class="pre">kernelSize,</span> <span class="pre">Weights</span> <span class="pre">kernelWeights,</span> <span class="pre">Weights</span> <span class="pre">biasWeights)=0</span> <span class="pre">-&gt;</span> <span class="pre">IDeconvolutionLayer</span> <span class="pre">*</span></code></p>
<p>add a deconvolution layer to the network</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>*</em>) – the input tensor to the layer</li>
<li><strong>nbOutputMaps</strong> (<em>*</em>) – the number of output feature maps</li>
<li><strong>kernelSize</strong> (<em>*</em>) – the HW-dimensions of the convolution kernel</li>
<li><strong>kernelWeights</strong> (<em>*</em>) – the kernel weights for the convolution</li>
<li><strong>biasWeights</strong> (<em>*</em>) – the optional bias weights for the convolution</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the new deconvolution layer, or null if it could not be created</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_element_wise">
<code class="descname">add_element_wise</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_element_wise" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">addElementWise(ITensor</span> <span class="pre">&amp;input1,</span> <span class="pre">ITensor</span> <span class="pre">&amp;input2,</span> <span class="pre">ElementWiseOperation</span> <span class="pre">op)=0</span> <span class="pre">-&gt;</span> <span class="pre">IElementWiseLayer</span> <span class="pre">*</span></code></p>
<p>add an elementwise layer to the network</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input1</strong> (<em>*</em>) – the first input tensor to the layer</li>
<li><strong>input2</strong> (<em>*</em>) – the second input tensor to the layer</li>
<li><strong>op</strong> (<em>*</em>) – the binary operation that the layer applies</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the new elementwise layer, or null if it could not be created</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_fully_connected">
<code class="descname">add_fully_connected</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_fully_connected" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">addFullyConnected(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">int</span> <span class="pre">nbOutputs,</span> <span class="pre">Weights</span> <span class="pre">kernelWeights,</span> <span class="pre">Weights</span> <span class="pre">biasWeights)=0</span> <span class="pre">-&gt;</span> <span class="pre">IFullyConnectedLayer</span> <span class="pre">*</span></code></p>
<p>add a fully connected layer to the network</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>*</em>) – the input tensor to the layer</li>
<li><strong>nbOutputs</strong> (<em>*</em>) – the number of outputs of the layer</li>
<li><strong>kernelWeights</strong> (<em>*</em>) – the kernel weights for the convolution</li>
<li><strong>biasWeights</strong> (<em>*</em>) – the optional bias weights for the convolution</li>
<li><strong>also</strong> (<em>See</em>) – </li>
<li><strong>input to a fully connected layer is automatically flattened to a tensor of the form NxCx1x1</strong><strong>, </strong><strong>and the output is of the form NxKx1x1</strong><strong>, </strong><strong>where C is the nunber of input activations per image</strong><strong>, </strong><strong>and K</strong> (<em>the</em>) – </li>
<li><strong>the number of outputs per image.</strong> (<em>is</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the new convolution layer, or null if it could not be created</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_input">
<code class="descname">add_input</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_input" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">addInput(const</span> <span class="pre">char</span> <span class="pre">*name,</span> <span class="pre">DataType</span> <span class="pre">type,</span> <span class="pre">Dims</span> <span class="pre">dimensions)=0</span> <span class="pre">-&gt;</span> <span class="pre">ITensor</span> <span class="pre">*</span></code></p>
<p>add an input tensor to the network</p>
<p>the name of the input tensor is used to find the index into the buffer array for an engine built from the network</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<em>*</em>) – the name of the tensor</li>
<li><strong>type</strong> (<em>*</em>) – the type of the data held in the tensor</li>
<li><strong>dimensions</strong> (<em>*</em>) – the dimensions of the tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>:param Only DataType::kFLOAT and DataType::kHALF are valid input tensor types. The volume of the dimension, including the maximum batch size, must be less than 2^30 elements.:
:param See also:
:type See also: ITensor</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">the new tensor or nullptr if there is an error</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_lrn">
<code class="descname">add_lrn</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_lrn" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">addLRN(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">int</span> <span class="pre">window,</span> <span class="pre">float</span> <span class="pre">alpha,</span> <span class="pre">float</span> <span class="pre">beta,</span> <span class="pre">float</span> <span class="pre">k)=0</span> <span class="pre">-&gt;</span> <span class="pre">ILRNLayer</span> <span class="pre">*</span></code></p>
<p>add a LRN layer to the network</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>*</em>) – the input tensor to the layer</li>
<li><strong>window</strong> (<em>*</em>) – the size of the window</li>
<li><strong>alpha</strong> (<em>*</em>) – the alpha value for the LRN computation</li>
<li><strong>beta</strong> (<em>*</em>) – the beta value for the LRN computation</li>
<li><strong>k</strong> (<em>*</em>) – the k value for the LRN computation</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the new LRN layer, or null if it could not be created</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_padding">
<code class="descname">add_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">addPadding(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">DimsHW</span> <span class="pre">prePadding,</span> <span class="pre">DimsHW</span> <span class="pre">postPadding)=0</span> <span class="pre">-&gt;</span> <span class="pre">IPaddingLayer</span> <span class="pre">*</span></code></p>
<p>Add a padding layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>*</em>) – the input tensor to the layer</li>
<li><strong>prePadding</strong> (<em>*</em>) – the padding to apply to the start of the tensor</li>
<li><strong>postPadding</strong> (<em>*</em>) – the padding to apply to the end of the tensor</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the new padding layer, or null if it could not be created</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_plugin">
<code class="descname">add_plugin</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_plugin" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">addPlugin(ITensor</span> <span class="pre">*const</span> <span class="pre">*inputs,</span> <span class="pre">int</span> <span class="pre">nbInputs,</span> <span class="pre">IPlugin</span> <span class="pre">&amp;plugin)=0</span> <span class="pre">-&gt;</span> <span class="pre">IPluginLayer</span> <span class="pre">*</span></code></p>
<p>add a plugin layer to the network</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inputs</strong> (<em>*</em>) – the input tensors to the layer</li>
<li><strong>nbInputs</strong> (<em>*</em>) – the number of input tensors</li>
<li><strong>plugin</strong> (<em>*</em>) – the layer plugin</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the new plugin layer, or null if it could not be created</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_pooling">
<code class="descname">add_pooling</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_pooling" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">addPooling(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">PoolingType</span> <span class="pre">type,</span> <span class="pre">DimsHW</span> <span class="pre">windowSize)=0</span> <span class="pre">-&gt;</span> <span class="pre">IPoolingLayer</span> <span class="pre">*</span></code></p>
<p>add a pooling layer to the network</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>*</em>) – the input tensor to the layer</li>
<li><strong>type</strong> (<em>*</em>) – the type of pooling to apply</li>
<li><strong>windowSize</strong> (<em>*</em>) – the size of the pooling window</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the new pooling layer, or null if it could not be created</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_rnn">
<code class="descname">add_rnn</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_rnn" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">addRNN(ITensor</span> <span class="pre">&amp;inputs,</span> <span class="pre">int</span> <span class="pre">layerCount,</span> <span class="pre">std::size_t</span> <span class="pre">hiddenSize,</span> <span class="pre">int</span> <span class="pre">maxSeqLen,</span> <span class="pre">RNNOperation</span> <span class="pre">op,</span> <span class="pre">RNNInputMode</span> <span class="pre">mode,</span> <span class="pre">RNNDirection</span> <span class="pre">dir,</span> <span class="pre">Weights</span> <span class="pre">weights,</span> <span class="pre">Weights</span> <span class="pre">bias)=0</span> <span class="pre">-&gt;</span> <span class="pre">IRNNLayer</span> <span class="pre">*</span></code></p>
<p>add an <cite>layerCount</cite> deep RNN layer to the network with a sequence length of <cite>maxSeqLen</cite> and <cite>hiddenSize</cite> internal state per layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>inputs</strong> (<em>*</em>) – the input tensor to the layer.</li>
<li><strong>layerCount</strong> (<em>*</em>) – the number of layers in the RNN.</li>
<li><strong>hiddenSize</strong> (<em>*</em>) – the size of the internal hidden state for each layer.</li>
<li><strong>maxSeqLen</strong> (<em>*</em>) – the maximum length of the time sequence.</li>
<li><strong>op</strong> (<em>*</em>) – the type of RNN to execute.</li>
<li><strong>mode</strong> (<em>*</em>) – the input mode for the RNN.</li>
<li><strong>dir</strong> (<em>*</em>) – the direction to run the RNN.</li>
<li><strong>weights</strong> (<em>*</em>) – the weights for the weight matrix parameters of the RNN.</li>
<li><strong>bias</strong> (<em>*</em>) – the weights for the bias vectors parameters of the RNN.</li>
<li><strong>layout for the input tensor is {1</strong><strong>, </strong><strong>T</strong><strong>, </strong><strong>N</strong><strong>, </strong><strong>C} and defined as follows</strong> (<em>The</em>) – </li>
<li><strong>T - The number of time sequences to be executed.</strong> (<em>*</em>) – </li>
<li><strong>N - The number of mini-batches for each time sequence.</strong> (<em>*</em>) – </li>
<li><strong>C - The size of data to be submitted to the RNN.</strong> (<em>*</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>:param The input tensors must be of the type DataType::kFLOAT or DataType::kHALF. The layout of the weights is row major and must be the same datatype as the input tensor. <cite>weights</cite> contain 8 matrices and:
:param <cite>bias</cite> contains 8 vectors.:
:param The RNN layer outputs up to three tensors. The first tensor has dim {1, T, N, C}, is the output of the RNN for each timestep, and defined as follows:
:param *   T - The number of sequences to be executed.:
:param *   N - The number of mini-batches for each time sequence.:
:param *   C - The hidden state for each layer. Equal to getHiddenSize() if getDirection is RNNDirection::kUNIDIRECTION, and 2x getHiddenSize() otherwise.:
:param The second tensor has dimension {1, L, N, H}, is the final hidden state of the RNN, and defined as follows.:
:param *   L - The number of layers in the RNN, equal to getLayerCount():
:param *   N - The number of mini-batches for each time sequence.:
:param *   H - The hidden state for each layer. Equal to getHiddenSize() if getDirection is RNNDirection::kUNIDIRECTION, and 2x getHiddenSize() otherwise.:
:param The third tensor has dimension {1, L, N, H}, is the final cell state of the RNN, and defined as follows.:
:param *   L - The number of layers in the RNN, equal to getLayerCount():
:param *   N - The number of mini-batches for each time sequence.:
:param *   H - The hidden state for each layer. Equal to getHiddenSize() if getDirection is RNNDirection::kUNIDIRECTION, and 2x getHiddenSize() otherwise.:
:param The third tensor is only available if getOperation() is RNNDirection::kLSTM.:</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the new RNN layer, or null if it could not be created.</em></li>
<li><strong>See also</strong> (<em>IRNNLayer::setW(), IRNNLayer::setU(), IRNNLayer::setB()</em>) – IRNNLayer</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_scale">
<code class="descname">add_scale</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_scale" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">addScale(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">ScaleMode</span> <span class="pre">mode,</span> <span class="pre">Weights</span> <span class="pre">shift,</span> <span class="pre">Weights</span> <span class="pre">scale,</span> <span class="pre">Weights</span> <span class="pre">power)=0</span> <span class="pre">-&gt;</span> <span class="pre">IScaleLayer</span> <span class="pre">*</span></code></p>
<p>add a Scale layer to the network</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<em>*</em>) – the input tensor to the layer</li>
<li><strong>mode</strong> (<em>*</em>) – the scaling mode</li>
<li><strong>shift</strong> (<em>*</em>) – the shift value</li>
<li><strong>scale</strong> (<em>*</em>) – the scale value</li>
<li><strong>power</strong> (<em>*</em>) – the power value</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>:param If the weights are available, then the size of weights are dependent on the on the ScaleMode. For ScaleMode::kUNIFORM, the number of weights is equal to 1. For ScaleMode::kCHANNEL, the number of:
:param weights is equal to the channel dimension. For ScaleMode::kELEMENTWISE, the number of weights is equal to the volume of the input.:
:param See also:
:type See also: IScaleLayer</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">the new Scale layer, or null if it could not be created</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_shuffle">
<code class="descname">add_shuffle</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_shuffle" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">addShuffle(ITensor</span> <span class="pre">&amp;input)=0</span> <span class="pre">-&gt;</span> <span class="pre">IShuffleLayer</span> <span class="pre">*</span></code></p>
<p>add a shuffle layer to the network</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input</strong> (<em>*</em>) – the input tensor to the layer</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">the new shuffle layer, or null if it could not be created</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_softmax">
<code class="descname">add_softmax</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_softmax" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">addSoftMax(ITensor</span> <span class="pre">&amp;input)=0</span> <span class="pre">-&gt;</span> <span class="pre">ISoftMaxLayer</span> <span class="pre">*</span></code></p>
<p>add a Scale layer to the network</p>
<p>See also: ISoftMaxLayer</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">the new SoftMax layer, or null if it could not be created</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.add_unary">
<code class="descname">add_unary</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.add_unary" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">addUnary(ITensor</span> <span class="pre">&amp;input,</span> <span class="pre">UnaryOperation</span> <span class="pre">operation)=0</span> <span class="pre">-&gt;</span> <span class="pre">IUnaryLayer</span> <span class="pre">*</span></code></p>
<p>Add a unary layer to the network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>*</em>) – the input tensor to the layer</li>
<li><strong>operation</strong> (<em>*</em>) – the operation to apply</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the new unary layer, or null if it could not be created</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.destroy">
<code class="descname">destroy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.destroy" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">destroy()=0</span></code></p>
<p>destroy this INetworkDefinition object</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.get_convolution_output_dimensions_formula">
<code class="descname">get_convolution_output_dimensions_formula</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.get_convolution_output_dimensions_formula" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getConvolutionOutputDimensionsFormula()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">IOutputDimensionsFormula</span> <span class="pre">&amp;</span></code></p>
<p>get the convolution output dimensions formula</p>
<p>Deprecated
this method does not currently work reliably and will be removed in a future release</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the formula from computing the convolution output dimensions</em></li>
<li><strong>See also</strong> (<em>IOutputDimensionsFormula setConvolutionOutputDimensionsFormula()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.get_deconvolution_output_dimensions_formula">
<code class="descname">get_deconvolution_output_dimensions_formula</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.get_deconvolution_output_dimensions_formula" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getDeconvolutionOutputDimensionsFormula()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">IOutputDimensionsFormula</span> <span class="pre">&amp;</span></code></p>
<p>get the deconvolution output dimensions formula</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the formula from computing the deconvolution output dimensions.</em></li>
<li><em>Deprecated</em></li>
<li><em>this method does not currently work reliably and will be removed in a future release</em></li>
<li><strong>See also</strong> (<em>IOutputDimensionsFormula setDeconvolutionOutputDimensionsFormula()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.get_input">
<code class="descname">get_input</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.get_input" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getInput(int</span> <span class="pre">index)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ITensor</span> <span class="pre">*</span></code></p>
<p>get the input tensor specified by the given index</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<em>*</em>) – the index of the input tensor</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the input tensor, or null if the index is out of range</em></li>
<li><strong>See also</strong> (<em>getNbInputs()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.get_layer">
<code class="descname">get_layer</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.get_layer" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getLayer(int</span> <span class="pre">index)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ILayer</span> <span class="pre">*</span></code></p>
<p>get the layer specified by the given index</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<em>*</em>) – the index of the layer</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the layer, or null if the index is out of range</em></li>
<li><strong>See also</strong> (<em>getNbLayers()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.get_nb_inputs">
<code class="descname">get_nb_inputs</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.get_nb_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getNbInputs()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the number of inputs in the network</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the number of inputs in the network</em></li>
<li><strong>See also</strong> (<em>getInput()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.get_nb_layers">
<code class="descname">get_nb_layers</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.get_nb_layers" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getNbLayers()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the number of layers in the network</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the number of layers in the network</em></li>
<li><strong>See also</strong> (<em>getLayer()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.get_nb_outputs">
<code class="descname">get_nb_outputs</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.get_nb_outputs" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getNbOutputs()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the number of outputs in the network</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the number of outputs in the network</em></li>
<li><strong>See also</strong> (<em>getOutput()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.get_output">
<code class="descname">get_output</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.get_output" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getOutput(int</span> <span class="pre">index)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ITensor</span> <span class="pre">*</span></code></p>
<p>get the output tensor specified by the given index</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<em>*</em>) – the index of the output tensor</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the output tensor, or null if the index is out of range</em></li>
<li><strong>See also</strong> (<em>getNbOutputs()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.get_pooling_output_dimensions_formula">
<code class="descname">get_pooling_output_dimensions_formula</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.get_pooling_output_dimensions_formula" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getPoolingOutputDimensionsFormula()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">IOutputDimensionsFormula</span> <span class="pre">&amp;</span></code></p>
<p>get the pooling output dimensions formula</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the formula from computing the pooling output dimensions</em></li>
<li><strong>See also</strong> (<em>IOutputDimensionsFormula setPoolingOutputDimensionsFormula()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.mark_output">
<code class="descname">mark_output</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.mark_output" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">markOutput(ITensor</span> <span class="pre">&amp;tensor)=0</span></code></p>
<p>mark a tensor as a network output</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>tensor</strong> (<em>*</em>) – the tensor to mark as an output tensor</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.set_convolution_output_dimensions_formula">
<code class="descname">set_convolution_output_dimensions_formula</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.set_convolution_output_dimensions_formula" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setConvolutionOutputDimensionsFormula(IOutputDimensionsFormula</span> <span class="pre">*formula)=0</span></code></p>
<p>set the convolution output dimensions formula</p>
<p>Deprecated
this method does not currently work reliably and will be removed in a future release</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>formula</strong> (<em>*</em>) – the formula from computing the convolution output dimensions. If null is passed, the default formula is used.</li>
<li><strong>default formula in each dimension is</strong><strong> (</strong><strong>inputDim + padding * 2 - kernelSize</strong><strong>) </strong><strong>/ stride + 1</strong> (<em>the</em>) – </li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.set_deconvolution_output_dimensions_formula">
<code class="descname">set_deconvolution_output_dimensions_formula</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.set_deconvolution_output_dimensions_formula" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setDeconvolutionOutputDimensionsFormula(IOutputDimensionsFormula</span> <span class="pre">*formula)=0</span></code></p>
<p>set the deconvolution output dimensions formula</p>
<p>Deprecated
this method does not currently work reliably and will be removed in a future release</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>formula</strong> (<em>*</em>) – the formula from computing the deconvolution output dimensions. If null is passed, the default formula is used.</li>
<li><strong>default formula in each dimension is</strong><strong> (</strong><strong>inputDim - 1</strong><strong>) </strong><strong>* stride + kernelSize - 2 * padding</strong> (<em>the</em>) – </li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.NetworkDefinition.set_pooling_output_dimensions_formula">
<code class="descname">set_pooling_output_dimensions_formula</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.NetworkDefinition.set_pooling_output_dimensions_formula" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setPoolingOutputDimensionsFormula(IOutputDimensionsFormula</span> <span class="pre">*formula)=0</span></code></p>
<p>set the pooling output dimensions formula</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>formula</strong> (<em>*</em>) – the formula from computing the pooling output dimensions. If null is passed, the default formula is used.</li>
<li><strong>default formula in each dimension is</strong><strong> (</strong><strong>inputDim + padding * 2 - kernelSize</strong><strong>) </strong><strong>/ stride + 1</strong> (<em>the</em>) – </li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="layertype">
<h3>LayerType<a class="headerlink" href="#layertype" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.LayerType">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">LayerType</code><a class="reference internal" href="../_modules/tensorrt/infer/_infer_enums.html#LayerType"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorrt.infer.LayerType" title="Permalink to this definition">¶</a></dt>
<dd><p>Available layer types</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="tensor">
<h3>Tensor<a class="headerlink" href="#tensor" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Tensor">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Tensor</code><a class="headerlink" href="#tensorrt.infer.Tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>a tensor in a network definition</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.Tensor.get_dimensions">
<code class="descname">get_dimensions</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.get_dimensions" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getDimensions()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Dims</span></code></p>
<p>Get the dimensions of a tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the dimensions of the layer</em></li>
<li><strong>See also</strong> (<em>setDimensions()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Tensor.get_name">
<code class="descname">get_name</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.get_name" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getName()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">const</span> <span class="pre">char</span> <span class="pre">*</span></code></p>
<p>get the tensor name</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the name, as a pointer to a NULL-terminated character sequence</em></li>
<li><strong>See also</strong> (<em>setName()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Tensor.get_type">
<code class="descname">get_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.get_type" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getType()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DataType</span></code></p>
<p>Get the data type of a tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the data type of the tensor</em></li>
<li><strong>See also</strong> (<em>setType()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Tensor.is_network_input">
<code class="descname">is_network_input</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.is_network_input" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">isNetworkInput()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>whether the tensor is a network input</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Tensor.is_network_output">
<code class="descname">is_network_output</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.is_network_output" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">isNetworkOutput()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>whether the tensor is a network output</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Tensor.set_dimensions">
<code class="descname">set_dimensions</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.set_dimensions" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setDimensions(Dims</span> <span class="pre">dimensions)=0</span></code></p>
<p>Set the dimensions of a tensor.</p>
<p>For a network input the name is assigned by the application. For a network output it is computed based on the layer parameters and the inputs to the layer. If a tensor size or a parameter is modified
in the network, the dimensions of all dependent tensors will be recomputed.</p>
<p>This call is only legal for network input tensors, since the dimensions of layer output tensors are inferred based on layer inputs and parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dimensions</strong> (<em>*</em>) – the dimensions of the tensor</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Tensor.set_name">
<code class="descname">set_name</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.set_name" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setName(const</span> <span class="pre">char</span> <span class="pre">*name)=0</span></code></p>
<p>Set the tensor name.</p>
<p>For a network input, the name is assigned by the application. For tensors which are layer outputs, a default name is assigned consisting of the layer name followed by the index of the output in
brackets.</p>
<p>This method copies the name string</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<em>*</em>) – the name</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Tensor.set_type">
<code class="descname">set_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Tensor.set_type" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setType(DataType</span> <span class="pre">type)=0</span></code></p>
<p>Set the data type of a tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>type</strong> (<em>*</em>) – the data type of the tensor</li>
<li><strong>type is unchanged if the type is invalid for the given tensor.</strong> (<em>The</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>:param If the tensor is a network input or output, then the tensor type cannot be DataType::kINT8.:
:param See also:
:type See also: getType()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="layer">
<h3>Layer<a class="headerlink" href="#layer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Layer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Layer</code><a class="headerlink" href="#tensorrt.infer.Layer" title="Permalink to this definition">¶</a></dt>
<dd><p>base class for all layer classes in a network definition</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.Layer.get_input">
<code class="descname">get_input</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Layer.get_input" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getInput(int</span> <span class="pre">index)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ITensor</span> <span class="pre">*</span></code></p>
<p>get the layer input corresponding to the given index</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<em>*</em>) – the index of the input tensor</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">the input tensor, or nullptr if the index is out of range</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Layer.get_name">
<code class="descname">get_name</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Layer.get_name" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getName()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">const</span> <span class="pre">char</span> <span class="pre">*</span></code></p>
<p>return the name of a layer</p>
<p>See also: setName()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Layer.get_nb_inputs">
<code class="descname">get_nb_inputs</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Layer.get_nb_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getNbInputs()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the number of inputs of a layer</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Layer.get_nb_outputs">
<code class="descname">get_nb_outputs</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Layer.get_nb_outputs" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getNbOutputs()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the number of outputs of a layer</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Layer.get_output">
<code class="descname">get_output</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Layer.get_output" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getOutput(int</span> <span class="pre">index)</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ITensor</span> <span class="pre">*</span></code></p>
<p>get the layer output corresponding to the given index</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">the indexed output tensor, or nullptr if the index is out of range</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Layer.get_type">
<code class="descname">get_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Layer.get_type" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getType()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">LayerType</span></code></p>
<p>return the type of a layer</p>
<p>See also: LayerType</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Layer.set_name">
<code class="descname">set_name</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Layer.set_name" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setName(const</span> <span class="pre">char</span> <span class="pre">*name)=0</span></code></p>
<p>set the name of a layer</p>
<p>this method copies the name string</p>
<p>See also: getName()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="convolutionlayer">
<h3>ConvolutionLayer<a class="headerlink" href="#convolutionlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ConvolutionLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ConvolutionLayer</code><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>a convolution layer in a network definition</p>
<p>This layer performs a correlation operation between 3-dimensional filter with a 4-dimensional tensor to produce another 4-dimensional tensor.</p>
<p>The HW output size of the convolution is set according to the <cite>INetworkCustomDimensions</cite> set in INetworkDefinition::setCustomConvolutionDimensions().</p>
<p>An optional bias argument is supported, which adds a per-channel constant to each value in the output.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.get_bias_weights">
<code class="descname">get_bias_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.get_bias_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getBiasWeights()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>get the bias weights for the convolution</p>
<p>See also: getBiasWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.get_dilation">
<code class="descname">get_dilation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.get_dilation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getDilation()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>get the dilation for a convolution</p>
<p>See also: setDilation</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.get_kernel_size">
<code class="descname">get_kernel_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.get_kernel_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getKernelSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>get the HW kernel size of the convolution</p>
<p>See also: setKernelSize()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.get_kernel_weights">
<code class="descname">get_kernel_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.get_kernel_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getKernelWeights()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>get the kernel weights for the convolution</p>
<p>See also: setNbGroups()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.get_nb_groups">
<code class="descname">get_nb_groups</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.get_nb_groups" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getNbGroups()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>set the number of groups for a convolution</p>
<p>See also: setNbGroups()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.get_nb_output_maps">
<code class="descname">get_nb_output_maps</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.get_nb_output_maps" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getNbOutputMaps()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the number of output maps for the convolution</p>
<p>See also: setNbOutputMaps()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.get_padding">
<code class="descname">get_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.get_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getPadding()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>get the padding of the convolution</p>
<p>See also: setPadding()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.get_stride">
<code class="descname">get_stride</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.get_stride" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getStride()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>get the stride of the convolution</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.set_bias_weights">
<code class="descname">set_bias_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.set_bias_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setBiasWeights(Weights</span> <span class="pre">weights)=0</span></code></p>
<p>set the bias weights for the convolution</p>
<p>Bias is optional. To omit bias, set the count value of the weights structure to zero.</p>
<p>The bias is applied per-channel, so the number of weights (if non-zero) must be equal to the number of output feature maps.</p>
<p>See also: getBiasWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.set_dilation">
<code class="descname">set_dilation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.set_dilation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setDilation(DimsHW</span> <span class="pre">dims)=0</span></code></p>
<p>set the dilation for a convolution</p>
<p>default (1,1)</p>
<p>See also: getDilation</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.set_kernel_size">
<code class="descname">set_kernel_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.set_kernel_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setKernelSize(DimsHW</span> <span class="pre">kernelSize)=0</span></code></p>
<p>set the HW kernel size of the convolution</p>
<p>See also: getKernelSize()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.set_kernel_weights">
<code class="descname">set_kernel_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.set_kernel_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setKernelWeights(Weights</span> <span class="pre">weights)=0</span></code></p>
<p>set the kernel weights for the convolution</p>
<p>The weights are specified as a contiguous array in <cite>GKCRS</cite> order, where <cite>G</cite> is the number of groups, <cite>K</cite> the number of output feature maps, <cite>C</cite> the number of input channels, and <cite>R</cite> and <cite>S</cite> are the
height and width of the filter</p>
<p>See also: getWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.set_nb_groups">
<code class="descname">set_nb_groups</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.set_nb_groups" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setNbGroups(int</span> <span class="pre">nbGroups)=0</span></code></p>
<p>set the number of groups for a convolution</p>
<p>The input tensor channels are divided into <cite>nbGroups</cite> groups, and a convolution is executed for each group, using a filter per group. The results of the group convolutions are concatenated to form the
output.</p>
<p>note: When using groups in int8 mode, the size of the groups (i.e. the channel count divided by the group count) must be a multiple of 4 for both input and output.</p>
<p>default: 1</p>
<p>See also: getNbGroups()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.set_nb_output_maps">
<code class="descname">set_nb_output_maps</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.set_nb_output_maps" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setNbOutputMaps(int</span> <span class="pre">nbOutputMaps)=0</span></code></p>
<p>set the number of output maps for the convolution</p>
<p>See also: getNbOutputMaps()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.set_padding">
<code class="descname">set_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.set_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setPadding(DimsHW</span> <span class="pre">padding)=0</span></code></p>
<p>set the padding of the convolution</p>
<p>The input will be zero-padded by this number of elements in the height and width directions. Padding is symmetric.</p>
<p>default: (0,0)</p>
<p>See also: getPadding()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConvolutionLayer.set_stride">
<code class="descname">set_stride</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConvolutionLayer.set_stride" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setStride(DimsHW</span> <span class="pre">stride)=0</span></code></p>
<p>get the stride of the convolution</p>
<p>default: (1,1)</p>
<p>See also: setStride()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="fullyconnectedlayer">
<h3>FullyConnectedLayer<a class="headerlink" href="#fullyconnectedlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.FullyConnectedLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">FullyConnectedLayer</code><a class="headerlink" href="#tensorrt.infer.FullyConnectedLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>a fully connected layer in a network definition</p>
<p>The layer automatically reshapes its input into a <cite>NxCx1x1</cite> tensor, then applies a matrix multiplication to create an NxKx1x1 output. An optional bias argument is supported.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.FullyConnectedLayer.get_bias_weights">
<code class="descname">get_bias_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.FullyConnectedLayer.get_bias_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getBiasWeights()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>get the bias weights</p>
<p>See also: setBiasWeightsWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.FullyConnectedLayer.get_kernel_weights">
<code class="descname">get_kernel_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.FullyConnectedLayer.get_kernel_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getKernelWeights()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>get the kernel weights.</p>
<p>See also: setKernelWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.FullyConnectedLayer.get_nb_output_channels">
<code class="descname">get_nb_output_channels</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.FullyConnectedLayer.get_nb_output_channels" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getNbOutputChannels()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>set the number of outputs from the fully connected layer</p>
<p>See also: setNbOutputChannels()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.FullyConnectedLayer.set_bias_weights">
<code class="descname">set_bias_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.FullyConnectedLayer.set_bias_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setBiasWeights(Weights</span> <span class="pre">weights)=0</span></code></p>
<p>set the bias weights</p>
<p>Bias is optional. To omit bias, set the count value in the weights structure to zero.</p>
<p>See also: getBiasWeightsWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.FullyConnectedLayer.set_kernel_weights">
<code class="descname">set_kernel_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.FullyConnectedLayer.set_kernel_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setKernelWeights(Weights</span> <span class="pre">weights)=0</span></code></p>
<p>set the kernel weights. The expected format is an array of KC values, where K is the number of outputs and C is the number of inputs.</p>
<p>See also: getKernelWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.FullyConnectedLayer.set_nb_output_channels">
<code class="descname">set_nb_output_channels</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.FullyConnectedLayer.set_nb_output_channels" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setNbOutputChannels(int</span> <span class="pre">nbOutputs)=0</span></code></p>
<p>set the number of outputs from the fully connected layer</p>
<p>See also: getNbOutputChannels()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="activationlayer">
<h3>ActivationLayer<a class="headerlink" href="#activationlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ActivationLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ActivationLayer</code><a class="headerlink" href="#tensorrt.infer.ActivationLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>an Activation layer in a network definition</p>
<p>this layer applies a per-element activation function to its input.</p>
<p>The output has the same shape as the input.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.ActivationLayer.get_activation_type">
<code class="descname">get_activation_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ActivationLayer.get_activation_type" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getActivationType()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ActivationType</span></code></p>
<p>get the type of activation to be performed</p>
<p>See also: setActivationType(), ActivationType</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ActivationLayer.set_activation_type">
<code class="descname">set_activation_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ActivationLayer.set_activation_type" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setActivationType(ActivationType</span> <span class="pre">type)=0</span></code></p>
<p>set the type of activation to be performed</p>
<p>See also: getActivationType(), ActivationType</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="activationtype">
<h3>ActivationType<a class="headerlink" href="#activationtype" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ActivationType">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ActivationType</code><a class="reference internal" href="../_modules/tensorrt/infer/_infer_enums.html#ActivationType"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorrt.infer.ActivationType" title="Permalink to this definition">¶</a></dt>
<dd><p>Type of activation function</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="poolinglayer">
<h3>PoolingLayer<a class="headerlink" href="#poolinglayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.PoolingLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">PoolingLayer</code><a class="headerlink" href="#tensorrt.infer.PoolingLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>a Pooling layer in a network definition</p>
<p>The layer applies a reduction operation within a window over the input.</p>
<p>The output size is determined from the input size using the formula set by INetworkDefinition::setCustomPoolingDimensions().</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.get_average_count_excludes_padding">
<code class="descname">get_average_count_excludes_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.get_average_count_excludes_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getAverageCountExcludesPadding()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>get whether exclusive pooling uses as a denominator the overlap area betwen the window and the unpadded input.</p>
<p>See also: setAverageCountExcludesPadding()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.get_blend_factor">
<code class="descname">get_blend_factor</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.get_blend_factor" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getBlendFactor()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p>
<p>get the blending factor for the max_average_blend mode: max_average_blendPool = (1-blendFactor)*maxPool + blendFactor*avgPool blendFactor is a user value in [0,1] with the default value of 0.0 In
modes other than kMAX_AVERAGE_BLEND, blendFactor is ignored</p>
<p>See also: setBlendFactor()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.get_padding">
<code class="descname">get_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.get_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getPadding()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>get the padding for pooling</p>
<p>default: 0</p>
<p>See also: getStride()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.get_pooling_type">
<code class="descname">get_pooling_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.get_pooling_type" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getPoolingType()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">PoolingType</span></code></p>
<p>get the type of activation to be performed</p>
<p>See also: setPoolingType(), PoolingType</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.get_stride">
<code class="descname">get_stride</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.get_stride" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getStride()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>get the stride for pooling</p>
<p>See also: setStride()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.get_window_size">
<code class="descname">get_window_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.get_window_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getWindowSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>get the window size for pooling</p>
<p>See also: setWindowSize()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.set_average_count_excludes_padding">
<code class="descname">set_average_count_excludes_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.set_average_count_excludes_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setAverageCountExcludesPadding(bool</span> <span class="pre">exclusive)=0</span></code></p>
<p>set whether average pooling uses as a denominator the overlap area between the window and the unpadded input. If this is not set, the denominator is the overlap between the pooling window and the
padded input.</p>
<p>default: true</p>
<p>See also: getAverageCountExcludesPadding()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.set_blend_factor">
<code class="descname">set_blend_factor</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.set_blend_factor" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setBlendFactor(float</span> <span class="pre">blendFactor)=0</span></code></p>
<p>set the blending factor for the max_average_blend mode: max_average_blendPool = (1-blendFactor)*maxPool + blendFactor*avgPool blendFactor is a user value in [0,1] with the default value of 0.0 This
value only applies for the kMAX_AVERAGE_BLEND mode.</p>
<p>See also: getBlendFactor()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.set_padding">
<code class="descname">set_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.set_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setPadding(DimsHW</span> <span class="pre">padding)=0</span></code></p>
<p>set the padding for pooling</p>
<p>default: 0</p>
<p>See also: getStride()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.set_pooling_type">
<code class="descname">set_pooling_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.set_pooling_type" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setPoolingType(PoolingType</span> <span class="pre">type)=0</span></code></p>
<p>set the type of activation to be performed</p>
<p>See also: getPoolingType(), PoolingType</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.set_stride">
<code class="descname">set_stride</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.set_stride" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setStride(DimsHW</span> <span class="pre">stride)=0</span></code></p>
<p>set the stride for pooling</p>
<p>default: 1</p>
<p>See also: getStride()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PoolingLayer.set_window_size">
<code class="descname">set_window_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PoolingLayer.set_window_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setWindowSize(DimsHW</span> <span class="pre">windowSize)=0</span></code></p>
<p>set the window size for pooling</p>
<p>See also: getWindowSize()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="poolingtype">
<h3>PoolingType<a class="headerlink" href="#poolingtype" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.PoolingType">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">PoolingType</code><a class="reference internal" href="../_modules/tensorrt/infer/_infer_enums.html#PoolingType"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorrt.infer.PoolingType" title="Permalink to this definition">¶</a></dt>
<dd><p>Type of pooling layer</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="lrnlayer">
<h3>LRNLayer<a class="headerlink" href="#lrnlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.LRNLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">LRNLayer</code><a class="headerlink" href="#tensorrt.infer.LRNLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>a LRN layer in a network definition</p>
<p>The output size is the same as the input size</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.LRNLayer.get_alpha">
<code class="descname">get_alpha</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.LRNLayer.get_alpha" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getAlpha()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p>
<p>get the LRN alpha value.</p>
<p>See also: setAlpha()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.LRNLayer.get_beta">
<code class="descname">get_beta</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.LRNLayer.get_beta" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getBeta()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p>
<p>get the LRN beta value.</p>
<p>See also: setBeta()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.LRNLayer.get_k">
<code class="descname">get_k</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.LRNLayer.get_k" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getK()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p>
<p>get the LRN K value.</p>
<p>See also: setK()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.LRNLayer.get_window_size">
<code class="descname">get_window_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.LRNLayer.get_window_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getWindowSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the LRN window size.</p>
<p>See also: getWindowStride()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.LRNLayer.set_alpha">
<code class="descname">set_alpha</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.LRNLayer.set_alpha" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setAlpha(float</span> <span class="pre">alpha)=0</span></code></p>
<p>set the LRN alpha value.</p>
<p>The valid range is [-1e20, 1e20].</p>
<p>See also: getAlpha()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.LRNLayer.set_beta">
<code class="descname">set_beta</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.LRNLayer.set_beta" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setBeta(float</span> <span class="pre">beta)=0</span></code></p>
<p>set the LRN beta value.</p>
<p>The valid range is [0.01, 1e5f].</p>
<p>See also: getBeta()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.LRNLayer.set_k">
<code class="descname">set_k</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.LRNLayer.set_k" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setK(float</span> <span class="pre">k)=0</span></code></p>
<p>set the LRN K value.</p>
<p>The valid range is [1e-5, 1e10].</p>
<p>See also: getK()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.LRNLayer.set_window_size">
<code class="descname">set_window_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.LRNLayer.set_window_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setWindowSize(int</span> <span class="pre">windowSize)=0</span></code></p>
<p>set the LRN window size.</p>
<p>The window size must be odd and in the range of [1, 15]</p>
<p>See also: setWindowStride()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="scalelayer">
<h3>ScaleLayer<a class="headerlink" href="#scalelayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ScaleLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ScaleLayer</code><a class="headerlink" href="#tensorrt.infer.ScaleLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>a Scale layer in a network definition</p>
<p>this layer applies a per-element computation to its input:</p>
<p><cite>output</cite> = (<cite>input*</cite> <cite>scale</cite> + <cite>shift</cite>)^ <cite>power</cite></p>
<p>The coefficients can be applied on a per-tensor, per-channel, or per-element basis.</p>
<p>if the count value in the weights is 0, a default is used. The default shift is 0, and the default power and scale are 1.</p>
<p>The output size is the same as the input size.</p>
<p>See also: ScaleMode</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.ScaleLayer.get_mode">
<code class="descname">get_mode</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ScaleLayer.get_mode" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getMode()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ScaleMode</span></code></p>
<p>set the scale mode.</p>
<p>See also: setMode()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ScaleLayer.get_power">
<code class="descname">get_power</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ScaleLayer.get_power" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getPower()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>get the power value.</p>
<p>See also: setPower()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ScaleLayer.get_scale">
<code class="descname">get_scale</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ScaleLayer.get_scale" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getScale()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>get the scale value.</p>
<p>See also: setScale()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ScaleLayer.get_shift">
<code class="descname">get_shift</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ScaleLayer.get_shift" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getShift()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>get the shift value.</p>
<p>See also: setShift()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ScaleLayer.set_mode">
<code class="descname">set_mode</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ScaleLayer.set_mode" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setMode(ScaleMode</span> <span class="pre">mode)=0</span></code></p>
<p>set the scale mode.</p>
<p>See also: getMode()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ScaleLayer.set_power">
<code class="descname">set_power</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ScaleLayer.set_power" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setPower(Weights</span> <span class="pre">power)=0</span></code></p>
<p>set the power value.</p>
<p>See also: getPower()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ScaleLayer.set_scale">
<code class="descname">set_scale</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ScaleLayer.set_scale" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setScale(Weights</span> <span class="pre">scale)=0</span></code></p>
<p>set the scale value.</p>
<p>See also: getScale()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ScaleLayer.set_shift">
<code class="descname">set_shift</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ScaleLayer.set_shift" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setShift(Weights</span> <span class="pre">shift)=0</span></code></p>
<p>set the shift value.</p>
<p>See also: getShift()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="scalemode">
<h3>ScaleMode<a class="headerlink" href="#scalemode" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ScaleMode">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ScaleMode</code><a class="reference internal" href="../_modules/tensorrt/infer/_infer_enums.html#ScaleMode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorrt.infer.ScaleMode" title="Permalink to this definition">¶</a></dt>
<dd><p>Scale mode</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="softmaxlayer">
<h3>SoftmaxLayer<a class="headerlink" href="#softmaxlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.SoftmaxLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">SoftmaxLayer</code><a class="headerlink" href="#tensorrt.infer.SoftmaxLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>a Softmax layer in a network definition</p>
<p>This layer applies a per-channel softmax to its input</p>
<p>The output size is the same as the input size.</p>
<p>C++ includes: NvInfer.h</p>
</dd></dl>

</div>
<div class="section" id="concatenationlayer">
<h3>ConcatenationLayer<a class="headerlink" href="#concatenationlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ConcatenationLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ConcatenationLayer</code><a class="headerlink" href="#tensorrt.infer.ConcatenationLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>a concatenation layer in a network definition</p>
<p>The output size is the sum of all tensors after concatenated across channels.</p>
<p>C++ includes: NvInfer.h</p>
</dd></dl>

</div>
<div class="section" id="deconvolutionlayer">
<h3>DeconvolutionLayer<a class="headerlink" href="#deconvolutionlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.DeconvolutionLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">DeconvolutionLayer</code><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>a deconvolution layer in a network definition</p>
<p>The output size is defined using the formula set by INetworkDefinition::setDeconvolutionOutputDimensionsFormula()</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.get_bias_weights">
<code class="descname">get_bias_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.get_bias_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getBiasWeights()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>get the bias weights for the deconvolution</p>
<p>See also: getBiasWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.get_kernel_size">
<code class="descname">get_kernel_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.get_kernel_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getKernelSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>get the HW kernel size of the deconvolution</p>
<p>See also: setKernelSize()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.get_kernel_weights">
<code class="descname">get_kernel_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.get_kernel_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getKernelWeights()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>get the kernel weights for the deconvolution</p>
<p>See also: setNbGroups()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.get_nb_groups">
<code class="descname">get_nb_groups</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.get_nb_groups" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getNbGroups()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>set the number of groups for a deconvolution</p>
<p>See also: setNbGroups()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.get_nb_output_maps">
<code class="descname">get_nb_output_maps</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.get_nb_output_maps" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getNbOutputMaps()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the number of output feature maps for the deconvolution</p>
<p>See also: setNbOutputMaps()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.get_padding">
<code class="descname">get_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.get_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getPadding()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>get the padding of the deconvolution</p>
<p>See also: setPadding()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.get_stride">
<code class="descname">get_stride</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.get_stride" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getStride()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>get the stride of the deconvolution</p>
<p>default: (1,1)</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.set_bias_weights">
<code class="descname">set_bias_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.set_bias_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setBiasWeights(Weights</span> <span class="pre">weights)=0</span></code></p>
<p>set the bias weights for the deconvolution</p>
<p>Bias is optional. To omit bias, set the count value of the weights structure to zero.</p>
<p>The bias is applied per-feature-map, so the number of weights (if non-zero) must be equal to the number of output feature maps.</p>
<p>See also: getBiasWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.set_kernel_size">
<code class="descname">set_kernel_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.set_kernel_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setKernelSize(DimsHW</span> <span class="pre">kernelSize)=0</span></code></p>
<p>set the HW kernel size of the convolution</p>
<p>See also: getKernelSize()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.set_kernel_weights">
<code class="descname">set_kernel_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.set_kernel_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setKernelWeights(Weights</span> <span class="pre">weights)=0</span></code></p>
<p>set the kernel weights for the deconvolution</p>
<p>The weights are specified as a contiguous array in <cite>CKRS</cite> order, where <cite>C</cite> the number of input channels, <cite>K</cite> the number of output feature maps, and <cite>R</cite> and <cite>S</cite> are the height and width of the filter</p>
<p>&#64; see getWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.set_nb_groups">
<code class="descname">set_nb_groups</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.set_nb_groups" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setNbGroups(int</span> <span class="pre">nbGroups)=0</span></code></p>
<p>set the number of groups for a deconvolution</p>
<p>The input tensor channels are divided into <cite>nbGroups</cite> groups, and a deconvolution is executed for each group, using a filter per group. The results of the group convolutions are concatenated to form
the output.</p>
<p>note: When using groups in int8 mode, the size of the groups (i.e. the channel count divided by the group count) must be a multiple of 4 for both input and output.</p>
<p>default: 1</p>
<p>See also: getNbGroups()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.set_nb_output_maps">
<code class="descname">set_nb_output_maps</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.set_nb_output_maps" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setNbOutputMaps(int</span> <span class="pre">nbOutputMaps)=0</span></code></p>
<p>set the number of output feature maps for the deconvolution</p>
<p>See also: getNbOutputMaps()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.set_padding">
<code class="descname">set_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.set_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setPadding(DimsHW</span> <span class="pre">padding)=0</span></code></p>
<p>set the padding of the deconvolution</p>
<p>The input will be zero-padded by this number of elements in the height and width directions. Padding is symmetric.</p>
<p>default: (0,0)</p>
<p>See also: getPadding()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.DeconvolutionLayer.set_stride">
<code class="descname">set_stride</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.DeconvolutionLayer.set_stride" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setStride(DimsHW</span> <span class="pre">stride)=0</span></code></p>
<p>get the stride of the deconvolution</p>
<p>See also: setStride()</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="elementwiselayer">
<h3>ElementWiseLayer<a class="headerlink" href="#elementwiselayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ElementWiseLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ElementWiseLayer</code><a class="headerlink" href="#tensorrt.infer.ElementWiseLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>a elementwise layer in a network definition</p>
<p>This layer applies a per-element binary operation between corresponding elements of two tensors.</p>
<p>The input dimensions of the two input tensors must be equal, and the output tensor is the same size as each input.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.ElementWiseLayer.get_operation">
<code class="descname">get_operation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ElementWiseLayer.get_operation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getOperation()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ElementWiseOperation</span></code></p>
<p>get the binary operation for the layer</p>
<p>See also: setOperation(), ElementWiseOperation</p>
<blockquote>
<div>setBiasWeights()</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ElementWiseLayer.set_operation">
<code class="descname">set_operation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ElementWiseLayer.set_operation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setOperation(ElementWiseOperation</span> <span class="pre">type)=0</span></code></p>
<p>set the binary operation for the layer</p>
<p>See also: getOperation(), ElementWiseOperation</p>
<blockquote>
<div>getBiasWeights()</div></blockquote>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="elementwiseoperation">
<h3>ElementWiseOperation<a class="headerlink" href="#elementwiseoperation" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ElementWiseOperation">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ElementWiseOperation</code><a class="reference internal" href="../_modules/tensorrt/infer/_infer_enums.html#ElementWiseOperation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorrt.infer.ElementWiseOperation" title="Permalink to this definition">¶</a></dt>
<dd><p>Type of operation for the layer</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="shufflelayer">
<h3>ShuffleLayer<a class="headerlink" href="#shufflelayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ShuffleLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ShuffleLayer</code><a class="headerlink" href="#tensorrt.infer.ShuffleLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>layer type for shuffling data</p>
<p>this class shuffles data by applying applying in sequence: a transpose operation, a reshape operation and a second transpose operation. The dimension types of the output are those of the reshape
dimension.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.ShuffleLayer.get_first_transpose">
<code class="descname">get_first_transpose</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ShuffleLayer.get_first_transpose" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getFirstTranspose()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Permutation</span></code></p>
<p>get the permutation applied by the first transpose operation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the dimension permutation applied before the reshape</em></li>
<li><strong>See also</strong> (<em>setFirstTranspose</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ShuffleLayer.get_reshape_dimensions">
<code class="descname">get_reshape_dimensions</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ShuffleLayer.get_reshape_dimensions" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getReshapeDimensions()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Dims</span></code></p>
<p>get the reshaped dimensions</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">the reshaped dimensions</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ShuffleLayer.get_second_transpose">
<code class="descname">get_second_transpose</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ShuffleLayer.get_second_transpose" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getSecondTranspose()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Permutation</span></code></p>
<p>get the permutation applied by the second transpose operation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the dimension permutation applied after the reshape</em></li>
<li><strong>See also</strong> (<em>setSecondTranspose</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ShuffleLayer.set_first_transpose">
<code class="descname">set_first_transpose</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ShuffleLayer.set_first_transpose" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setFirstTranspose(Permutation</span> <span class="pre">permutation)=0</span></code></p>
<p>set the permutation applied by the first transpose operation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>permutation</strong> (<em>*</em>) – the dimension permutation applied before the reshape</li>
<li><strong>default is the identity permutation.</strong> (<em>the</em>) – </li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ShuffleLayer.set_reshape_dimensions">
<code class="descname">set_reshape_dimensions</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ShuffleLayer.set_reshape_dimensions" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setReshapeDimensions(Dims</span> <span class="pre">dimensions)=0</span></code></p>
<p>set the reshaped dimensions</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dimensions</strong> (<em>*</em>) – the reshaped dimensions</li>
<li><strong>specifying the new dimensions</strong><strong>, </strong><strong>0 means copy from the input</strong><strong>, </strong><strong>and -1 means infer the dimension from the input and the other dimensions.</strong> (<em>When</em>) – </li>
<li><strong>product of the new dimensions must be equal to the product of the old.</strong> (<em>The</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ShuffleLayer.set_second_transpose">
<code class="descname">set_second_transpose</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ShuffleLayer.set_second_transpose" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setSecondTranspose(Permutation</span> <span class="pre">permutation)=0</span></code></p>
<p>set the permutation applied by the second transpose operation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>permutation</strong> (<em>*</em>) – the dimension permutation applied after the reshape</li>
<li><strong>default is the identity permutation.</strong> (<em>the</em>) – </li>
<li><strong>permutation is applied as outputDimension = permutation.order</strong><strong>[</strong><strong>inputDimension</strong><strong>]</strong><strong>, </strong><strong>so to permute from CHW order to HWC order</strong><strong>, </strong><strong>the required permutation is</strong><strong> [</strong><strong>1</strong><strong>, </strong><strong>0</strong><strong>, </strong><strong>2</strong><strong>]</strong> (<em>The</em>) – </li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="permutation">
<h3>Permutation<a class="headerlink" href="#permutation" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Permutation">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Permutation</code><a class="headerlink" href="#tensorrt.infer.Permutation" title="Permalink to this definition">¶</a></dt>
<dd><dl class="attribute">
<dt>
<code class="descname">* `order`</code></dt>
<dd><p><cite>int</cite> – the elements of the permutation. The permutation is applied as outputDimension = permutation.order[inputDimension], so to permute from CHW order to HWC order, the required permutation is [1, 2,
0], and to permute from HWC to CHW, the required permutation is [2, 0, 1].</p>
</dd></dl>

<dl class="attribute">
<dt id="tensorrt.infer.Permutation.order">
<code class="descname">order</code><a class="headerlink" href="#tensorrt.infer.Permutation.order" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="unarylayer">
<h3>UnaryLayer<a class="headerlink" href="#unarylayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.UnaryLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">UnaryLayer</code><a class="headerlink" href="#tensorrt.infer.UnaryLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>layer that represents a unary operation</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.UnaryLayer.get_operation">
<code class="descname">get_operation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.UnaryLayer.get_operation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getOperation()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">UnaryOperation</span></code></p>
<p>get the binary operation for the layer</p>
<p>See also: setOperation(), UnaryOperation</p>
<blockquote>
<div>setBiasWeights()</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.UnaryLayer.set_operation">
<code class="descname">set_operation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.UnaryLayer.set_operation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setOperation(UnaryOperation</span> <span class="pre">op)=0</span></code></p>
<p>set the binary operation for the layer</p>
<p>See also: getOperation(), UnaryOperation</p>
<blockquote>
<div>getBiasWeights()</div></blockquote>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="unaryoperation">
<h3>UnaryOperation<a class="headerlink" href="#unaryoperation" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.UnaryOperation">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">UnaryOperation</code><a class="reference internal" href="../_modules/tensorrt/infer/_infer_enums.html#UnaryOperation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorrt.infer.UnaryOperation" title="Permalink to this definition">¶</a></dt>
<dd><p>Type of operation for the layer</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="pluginlayer">
<h3>PluginLayer<a class="headerlink" href="#pluginlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.PluginLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">PluginLayer</code><a class="headerlink" href="#tensorrt.infer.PluginLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>layer type for plugins</p>
<p>See also: IPlugin</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.PluginLayer.get_plugin">
<code class="descname">get_plugin</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PluginLayer.get_plugin" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getPlugin()=0</span> <span class="pre">-&gt;</span> <span class="pre">IPlugin</span> <span class="pre">&amp;</span></code></p>
<p>get the plugin for the layer</p>
<p>See also: IPlugin</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="paddinglayer">
<h3>PaddingLayer<a class="headerlink" href="#paddinglayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.PaddingLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">PaddingLayer</code><a class="headerlink" href="#tensorrt.infer.PaddingLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>layer that represents a padding operation</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.PaddingLayer.get_post_padding">
<code class="descname">get_post_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PaddingLayer.get_post_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getPostPadding()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>set the padding that is applied at the end of the tensor</p>
<p>See also: setPostPadding</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PaddingLayer.get_pre_padding">
<code class="descname">get_pre_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PaddingLayer.get_pre_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getPrePadding()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">DimsHW</span></code></p>
<p>set the padding that is applied at the start of the tensor</p>
<p>See also: setPrePadding</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PaddingLayer.set_post_padding">
<code class="descname">set_post_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PaddingLayer.set_post_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setPostPadding(DimsHW</span> <span class="pre">padding)=0</span></code></p>
<p>set the padding that is applied at the end of the tensor</p>
<p>Negative padding results in trimming the edge by the specified amount</p>
<p>See also: getPostPadding</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.PaddingLayer.set_pre_padding">
<code class="descname">set_pre_padding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.PaddingLayer.set_pre_padding" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setPrePadding(DimsHW</span> <span class="pre">padding)=0</span></code></p>
<p>set the padding that is applied at the start of the tensor</p>
<p>Negative padding results in trimming the edge by the specified amount</p>
<p>See also: getPrePadding</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="rnnlayer">
<h3>RNNLayer<a class="headerlink" href="#rnnlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.RNNLayer">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">RNNLayer</code><a class="headerlink" href="#tensorrt.infer.RNNLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>a RNN layer in a network definition</p>
<p>This layer applies an RNN operation on the inputs.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_bias">
<code class="descname">get_bias</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_bias" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getBias()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>get the bias parameter vector for the RNN</p>
<p>See also: setB()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_cell_state">
<code class="descname">get_cell_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_cell_state" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getCellState()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ITensor</span> <span class="pre">*</span></code></p>
<p>Get the initial cell state of the RNN.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">nullptr if no initial cell tensor was specified, the initial cell data otherwise.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_data_length">
<code class="descname">get_data_length</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_data_length" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getDataLength()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the length of the data being processed by the RNN for use in computing other values.</p>
<p>See also: setHiddenState(), setCellState()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_direction">
<code class="descname">get_direction</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_direction" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getDirection()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">RNNDirection</span></code></p>
<p>get the direction of the RNN layer.</p>
<p>See also: setDirection(), RNNDirection</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_hidden_size">
<code class="descname">get_hidden_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_hidden_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getHiddenSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">std::size_t</span></code></p>
<p>get the size of the hidden layers.</p>
<p>The hidden size is the value of hiddenSize parameter passed into addRNN().</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>The internal hidden layer size for the RNN.</em></li>
<li><strong>See also</strong> (<em>getDirection(), addRNN()</em>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_hidden_state">
<code class="descname">get_hidden_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_hidden_state" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getHiddenState()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">ITensor</span> <span class="pre">*</span></code></p>
<p>Get the initial hidden state of the RNN.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">nullptr if no initial hidden tensor was specified, the initial hidden data otherwise.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_input_mode">
<code class="descname">get_input_mode</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_input_mode" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getInputMode()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">RNNInputMode</span></code></p>
<p>get the operation of the RNN layer.</p>
<p>See also: setInputMode(), RNNInputMode</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_layer_count">
<code class="descname">get_layer_count</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_layer_count" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getLayerCount()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">unsigned</span></code></p>
<p>get the number of layers in the RNN.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">The number of layers in the RNN.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_operation">
<code class="descname">get_operation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_operation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getOperation()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">RNNOperation</span></code></p>
<p>get the operation of the RNN layer.</p>
<p>See also: setOperation(), RNNOperation</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_seq_length">
<code class="descname">get_seq_length</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_seq_length" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getSeqLength()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the sequence length</p>
<p>The sequence length is the maximum number of time steps passed into the addRNN() function. This is also the maximum number of input tensors that the RNN can process at once.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">the maximum number of time steps that can be executed by a single call RNN layer.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.get_weights">
<code class="descname">get_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.get_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getWeights()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">Weights</span></code></p>
<p>get the W weights for the RNN</p>
<p>See also: setWeights()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.set_bias">
<code class="descname">set_bias</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.set_bias" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setBias(Weights</span> <span class="pre">bias)=0</span></code></p>
<p>set the weight parameters for the RNN.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>bias</strong> (<em>*</em>) – The weight structure holding the bias parameters.</td>
</tr>
</tbody>
</table>
<p>:param The trained weights for the bias parameter vector of the RNN. The data type must be of the type DataType::kFLOAT or DataType::kHALF. The weight structure holds two sets of parameters, one for W and:
:param one for R.:
:param See also:</p>
<blockquote>
<div><ul class="simple">
<li>L - The number of layers in the RNN, equal to getLayerCount()</li>
<li>N - The number of gates vectors in the RNN, dependent on getOperation(). – If getOperation() is RNNOperation::kRELU or RNNOperation::kTANH there are 2 gate vectors, with order Winput,
Uinput). – If getOperation() is RNNOperation::kLSTM there are 8 gate vectors, with order Wforget, Winput, Wcell, Woutput, Uforgot, Uinput, Ucell, Uoutput. – If getOperation() is
RNNOperation::kGRU there are 6 gate vectors, with order Wupdate, Wreset, Whidden, Uupdate, Ureset, Uhidden.</li>
<li>C - The size of each bias vector, which varies. — Each sub-vector consists of {getHiddenSize(), getHiddenSize()} elements if getDirection() is RNNDirection::kUNIDIRECTION. — Each sub-
vector consists of {getHiddenSize(), 2 x getHiddenSize()} elements if getDirection() is RNNDirection::kBIDIRECTION.</li>
</ul>
<p>getBias(), RNNOperation</p>
</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.set_cell_state">
<code class="descname">set_cell_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.set_cell_state" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setCellState(ITensor</span> <span class="pre">&amp;cell)=0</span></code></p>
<p>Set the initial cell state of the RNN with the provided <cite>cell</cite> ITensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>cell</strong> (<em>*</em>) – The initial cell state of the RNN.</li>
<li><strong>layout for cell is a linear layout of a 3D matrix</strong> (<em>The</em>) – </li>
<li><strong>C - The number of layers in the RNN</strong><strong>, </strong><strong>it must match getLayerCount</strong><strong>(</strong><strong>)</strong><strong></strong> (<em>*</em>) – </li>
<li><strong>H - The number of mini-batches for each time sequence.</strong> (<em>*</em>) – </li>
<li><strong>W - The size of the per layer hidden states</strong><strong>, </strong><strong>it must match getHiddenSize</strong><strong>(</strong><strong>)</strong><strong></strong> (<em>*</em>) – </li>
<li><strong>cell is not specified</strong><strong>, </strong><strong>then the initial cell state is set to zero.</strong> (<em>If</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>:param The amount of space required is doubled if getDirection() is RNNDirection::kBIDIRECTION with the bidirectional states coming after the unidirectional states.:
:param The cell state only affects LSTM RNN’s.:
:param See also:
:type See also: getCellState()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.set_direction">
<code class="descname">set_direction</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.set_direction" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setDirection(RNNDirection</span> <span class="pre">op)=0</span></code></p>
<p>set the direction of the RNN layer.</p>
<p>The direction determines if the RNN is run as a unidirectional(left to right) or bidirectional(left to right and right to left). In the RNNDirection::kBIDIRECTION case the output is concatenated
together, resulting in output size of 2x getHiddenSize().</p>
<p>See also: getDirection(), RNNDirection</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.set_hidden_state">
<code class="descname">set_hidden_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.set_hidden_state" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setHiddenState(ITensor</span> <span class="pre">&amp;hidden)=0</span></code></p>
<p>Set the initial hidden state of the RNN with the provided <cite>hidden</cite> ITensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>hidden</strong> (<em>*</em>) – The initial hidden state of the RNN.</li>
<li><strong>layout for hidden is a linear layout of a 3D matrix</strong> (<em>The</em>) – </li>
<li><strong>C - The number of layers in the RNN</strong><strong>, </strong><strong>it must match getLayerCount</strong><strong>(</strong><strong>)</strong><strong></strong> (<em>*</em>) – </li>
<li><strong>H - The number of mini-batches for each time sequence.</strong> (<em>*</em>) – </li>
<li><strong>W - The size of the per layer hidden states</strong><strong>, </strong><strong>it must match getHiddenSize</strong><strong>(</strong><strong>)</strong><strong></strong> (<em>*</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>:param The amount of space required is doubled if getDirection() is RNNDirection::kBIDIRECTION with the bidirectional states coming after the unidirectional states.:
:param If hidden is not specified, then the initial hidden state is set to zero.:
:param See also:
:type See also: getHiddenState()</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.set_input_mode">
<code class="descname">set_input_mode</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.set_input_mode" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setInputMode(RNNInputMode</span> <span class="pre">op)=0</span></code></p>
<p>set the operation of the RNN layer.</p>
<p>See also: getInputMode(), RNNInputMode</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.set_operation">
<code class="descname">set_operation</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.set_operation" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setOperation(RNNOperation</span> <span class="pre">op)=0</span></code></p>
<p>set the operation of the RNN layer.</p>
<p>See also: getOperation(), RNNOperation</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.RNNLayer.set_weights">
<code class="descname">set_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.RNNLayer.set_weights" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">setWeights(Weights</span> <span class="pre">weights)=0</span></code></p>
<p>set the weight parameters for the RNN.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>weights</strong> (<em>*</em>) – The weight structure holding the weight parameters.</td>
</tr>
</tbody>
</table>
<p>:param The trained weights for the weight parameter matrix of the RNN. The data type must be of the type DataType::kFLOAT or DataType::kHALF. The weight structure holds two sets of parameters, one for W and:
:param one for R.:
:param See also:</p>
<blockquote>
<div><ul class="simple">
<li>L - The number of layers in the RNN, equal to getLayerCount()</li>
<li>N - The number of gates matrices in the RNN, dependent on getOperation(). – If getOperation() is RNNOperation::kRELU or RNNOperation::kTANH there are 2 gate matrices, with order Winput,
Uinput). – If getOperation() is RNNOperation::kLSTM there are 8 gate matrices, with order Wforget, Winput, Wcell, Woutput, Uforgot, Uinput, Ucell, Uoutput. – If getOperation() is
RNNOperation::kGRU there are 6 gate matrices, with order Wupdate, Wreset, Whidden, Uupdate, Ureset, Uhidden.</li>
<li>C - The size of each weight matrix, which varies. – If the mode is RNNInputMode::kLINEAR and RNNDirection::kUNIDIRECTION then for first layer: — Each sub-matrix consists of
{getHiddenSize(), getDataLength()} – If the mode is RNNInputMode::kLINEAR and RNNDirection::kBIDIRECTION then for first layer: — Each sub-matrix consists of {getHiddenSize(),
getDataLength() + getHiddenSize()} – Otherwise all other layers have the dimensions: — Each sub-matrix consists of {getHiddenSize(), getHiddenSize()} elements if getDirection() is
RNNDirection::kUNIDIRECTION. — Each sub-matrix consists of {getHiddenSize(), 2 x getHiddenSize()} elements if getDirection() is RNNDirection::kBIDIRECTION.</li>
</ul>
<p>getWeights(), RNNOperation</p>
</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="rnnoperation">
<h3>RNNOperation<a class="headerlink" href="#rnnoperation" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.RNNOperation">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">RNNOperation</code><a class="reference internal" href="../_modules/tensorrt/infer/_infer_enums.html#RNNOperation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorrt.infer.RNNOperation" title="Permalink to this definition">¶</a></dt>
<dd><p>Type of operation for the layer</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="rnndirection">
<h3>RNNDirection<a class="headerlink" href="#rnndirection" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.RNNDirection">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">RNNDirection</code><a class="reference internal" href="../_modules/tensorrt/infer/_infer_enums.html#RNNDirection"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorrt.infer.RNNDirection" title="Permalink to this definition">¶</a></dt>
<dd><p>Direction for the RNN Layer</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="rnninputmode">
<h3>RNNInputMode<a class="headerlink" href="#rnninputmode" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.RNNInputMode">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">RNNInputMode</code><a class="reference internal" href="../_modules/tensorrt/infer/_infer_enums.html#RNNInputMode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorrt.infer.RNNInputMode" title="Permalink to this definition">¶</a></dt>
<dd><p>Input mode for RNN Layer</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="ioutputdimensionsformula">
<h3>IOutputDimensionsFormula<a class="headerlink" href="#ioutputdimensionsformula" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="int8-calibration">
<h2>Int8 Calibration<a class="headerlink" href="#int8-calibration" title="Permalink to this headline">¶</a></h2>
<div class="section" id="int8calibrator">
<h3>Int8Calibrator<a class="headerlink" href="#int8calibrator" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Int8Calibrator">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Int8Calibrator</code><a class="headerlink" href="#tensorrt.infer.Int8Calibrator" title="Permalink to this definition">¶</a></dt>
<dd><p>application-implemented interface for calibration</p>
<p>Calibration is a step performed by the builder when deciding suitable scale factors for 8-bit inference.</p>
<p>It must also provide a method for retrieving representative images which the calibration process can use to examine the distribution of activations. It may optionally implement a method for caching
the calibration result for reuse on subsequent runs.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.Int8Calibrator.get_algorithm">
<code class="descname">get_algorithm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8Calibrator.get_algorithm" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getAlgorithm()=0</span> <span class="pre">-&gt;</span> <span class="pre">CalibrationAlgoType</span></code></p>
<p>get the algorithm used by this calibrator</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">the algorithm used by the calibrator</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Int8Calibrator.get_batch">
<code class="descname">get_batch</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8Calibrator.get_batch" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getBatch(void</span> <span class="pre">*bindings[],</span> <span class="pre">const</span> <span class="pre">char</span> <span class="pre">*names[],</span> <span class="pre">int</span> <span class="pre">nbBindings)=0</span> <span class="pre">-&gt;</span> <span class="pre">bool</span></code></p>
<p>get a batch of input for calibration.</p>
<p>The batch size of the input must match the batch size returned by getBatchSize().</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>bindings</strong> (<em>*</em>) – an array of pointers to device memory that must be set to the memory containing each network input data</li>
<li><strong>names</strong> (<em>*</em>) – the names of the network input for each pointer in the binding array</li>
<li><strong>nbBindings</strong> (<em>*</em>) – the number of pointers in the bindings array</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>false if there are no more batches for calibration.</em></li>
<li><strong>See also</strong> (<em>getBatchSize()</em>)</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Int8Calibrator.get_batch_size">
<code class="descname">get_batch_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8Calibrator.get_batch_size" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getBatchSize()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">int</span></code></p>
<p>get the batch size used for calibration batches</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">the batch size</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Int8Calibrator.read_calibration_cache">
<code class="descname">read_calibration_cache</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8Calibrator.read_calibration_cache" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">readCalibrationCache(std::size_t</span> <span class="pre">&amp;length)=0</span> <span class="pre">-&gt;</span> <span class="pre">const</span> <span class="pre">void</span> <span class="pre">*</span></code></p>
<p>load a calibration cache.</p>
<p>calibration is potentially expensive, so it can be useful to generate the calibration data once, then use it on subsequent builds of the network. The cache includes the regression cutoff and quantile
values used to generate it, and will not be used if these do not batch the settings of the current calibrator. However, the network should also be recalibrated if its structure changes, or the input
data set changes, and it is the responsibility of the application to ensure this.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>length</strong> (<em>*</em>) – the length of the cached data, that should be set by the called function. If there is no data, this should be zero.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">a pointer to the cache, or nullptr if there is no data</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Int8Calibrator.write_calibration_cache">
<code class="descname">write_calibration_cache</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8Calibrator.write_calibration_cache" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">writeCalibrationCache(const</span> <span class="pre">void</span> <span class="pre">*ptr,</span> <span class="pre">std::size_t</span> <span class="pre">length)=0</span></code></p>
<p>save a calibration cache</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>ptr</strong> (<em>*</em>) – a pointer to the data to cache</li>
<li><strong>length</strong> (<em>*</em>) – the length in bytes of the data to cache</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="int8entropycalibrator">
<h3>Int8EntropyCalibrator<a class="headerlink" href="#int8entropycalibrator" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Int8EntropyCalibrator">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Int8EntropyCalibrator</code><a class="headerlink" href="#tensorrt.infer.Int8EntropyCalibrator" title="Permalink to this definition">¶</a></dt>
<dd><p>Entropy calibrator. This is the preferred calibrator, as it is less complicated than the legacy calibrator and produces better results</p>
<p>C++ includes: NvInfer.h</p>
</dd></dl>

</div>
<div class="section" id="int8legacycalibrator">
<h3>Int8LegacyCalibrator<a class="headerlink" href="#int8legacycalibrator" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Int8LegacyCalibrator">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Int8LegacyCalibrator</code><a class="headerlink" href="#tensorrt.infer.Int8LegacyCalibrator" title="Permalink to this definition">¶</a></dt>
<dd><p>legacy calibrator for compatibility with 2.0 EA. Will be removed in 2.2 Deprecated</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.Int8LegacyCalibrator.get_algorithm">
<code class="descname">get_algorithm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8LegacyCalibrator.get_algorithm" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getAlgorithm()</span> <span class="pre">-&gt;</span> <span class="pre">CalibrationAlgoType</span></code></p>
<p>Signal that this is the legacy calibrator</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Int8LegacyCalibrator.get_quantile">
<code class="descname">get_quantile</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8LegacyCalibrator.get_quantile" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getQuantile()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">double</span></code></p>
<p>the quantile (between 0 and 1) that will be used to select the region maximum when the quantile method is in use</p>
<p>see the user guide for more details on how the quantile is used.</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Int8LegacyCalibrator.get_regression_cutoff">
<code class="descname">get_regression_cutoff</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8LegacyCalibrator.get_regression_cutoff" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">getRegressionCutoff()</span> <span class="pre">const</span> <span class="pre">=0</span> <span class="pre">-&gt;</span> <span class="pre">double</span></code></p>
<p>the fraction (between 0 and 1) of the maximum used to define the regression cutoff when using regression to determine the region maximum</p>
<p>see the user guide for more details on how the regression cutoff is used</p>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Int8LegacyCalibrator.read_histogram_cache">
<code class="descname">read_histogram_cache</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8LegacyCalibrator.read_histogram_cache" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">readHistogramCache(std::size_t</span> <span class="pre">&amp;length)=0</span> <span class="pre">-&gt;</span> <span class="pre">const</span> <span class="pre">void</span> <span class="pre">*</span></code></p>
<p>load a histogram</p>
<p>histogram generation is potentially expensive, so it can be useful to generate the histograms once, then use them when exploring the space of calibrations. The histograms should be regenerated if the
network structure changes, or the input data set changes, and it is the responsibility of the application to ensure this.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>length</strong> (<em>*</em>) – the length of the cached data, that should be set by the called function. If there is no data, this should be zero.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">a pointer to the cache, or nullptr if there is no data</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="tensorrt.infer.Int8LegacyCalibrator.write_histogram_cache">
<code class="descname">write_histogram_cache</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Int8LegacyCalibrator.write_histogram_cache" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">writeHistogramCache(const</span> <span class="pre">void</span> <span class="pre">*ptr,</span> <span class="pre">std::size_t</span> <span class="pre">length)=0</span></code></p>
<p>save a histogram cache.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>ptr</strong> (<em>*</em>) – a pointer to the data to cache</li>
<li><strong>length</strong> (<em>*</em>) – the length in bytes of the data to cache</li>
<li><strong>also</strong> (<em>See</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="calibrationalgotype">
<h3>CalibrationAlgoType<a class="headerlink" href="#calibrationalgotype" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.CalibrationAlgoType">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">CalibrationAlgoType</code><a class="reference internal" href="../_modules/tensorrt/infer/_infer_enums.html#CalibrationAlgoType"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorrt.infer.CalibrationAlgoType" title="Permalink to this definition">¶</a></dt>
<dd><p>Type of int8 calibration algorithm</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
</div>
<div class="section" id="logger">
<h2>Logger<a class="headerlink" href="#logger" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id1">
<h3>Logger<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Logger">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Logger</code><a class="headerlink" href="#tensorrt.infer.Logger" title="Permalink to this definition">¶</a></dt>
<dd><p>application-implemented logging interface for the builder, engine and runtime.</p>
<p>Note that although a logger is passed on creation to each instance of a IBuilder or IRuntime interface, the logger is internally considered a singleton, and thus multiple instances of IRuntime and/or
IBuilder must all use the same logger</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.Logger.log">
<code class="descname">log</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Logger.log" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">log(Severity</span> <span class="pre">severity,</span> <span class="pre">const</span> <span class="pre">char</span> <span class="pre">*msg)=0</span></code></p>
<p>a callback implemented by the application to handle logging messages</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>severity</strong> (<em>*</em>) – the severity of the message</li>
<li><strong>msg</strong> (<em>*</em>) – the log message, null terminated.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="consolelogger">
<h3>ConsoleLogger<a class="headerlink" href="#consolelogger" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ConsoleLogger">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ConsoleLogger</code><a class="headerlink" href="#tensorrt.infer.ConsoleLogger" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="tensorrt.infer.ConsoleLogger.log">
<code class="descname">log</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConsoleLogger.log" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">log(Severity</span> <span class="pre">severity,</span> <span class="pre">const</span> <span class="pre">char</span> <span class="pre">*msg)=0</span></code></p>
<p>a callback implemented by the application to handle logging messages</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>severity</strong> (<em>*</em>) – the severity of the message</li>
<li><strong>msg</strong> (<em>*</em>) – the log message, null terminated.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="logseverity">
<h3>LogSeverity<a class="headerlink" href="#logseverity" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.LogSeverity">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">LogSeverity</code><a class="reference internal" href="../_modules/tensorrt/infer/_infer_enums.html#LogSeverity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#tensorrt.infer.LogSeverity" title="Permalink to this definition">¶</a></dt>
<dd><p>Log level specifier</p>
<dl class="docutils">
<dt>Base Class:</dt>
<dd>IntEnum</dd>
</dl>
</dd></dl>

</div>
</div>
<div class="section" id="profiler">
<h2>Profiler<a class="headerlink" href="#profiler" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id2">
<h3>Profiler<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.Profiler">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">Profiler</code><a class="headerlink" href="#tensorrt.infer.Profiler" title="Permalink to this definition">¶</a></dt>
<dd><p>application-implemented interface for profiling</p>
<p>When this class is added to an execution context, the profiler will be called once per layer for each invocation of execute(). Note that enqueue() does not currently support profiling.</p>
<p>the profiler will only be called after execution is complete. It has a small impact on execution time.</p>
<p>C++ includes: NvInfer.h</p>
<dl class="method">
<dt id="tensorrt.infer.Profiler.report_layer_time">
<code class="descname">report_layer_time</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.Profiler.report_layer_time" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">reportLayerTime(const</span> <span class="pre">char</span> <span class="pre">*layerName,</span> <span class="pre">float</span> <span class="pre">ms)=0</span></code></p>
<p>layer time reporting callback</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>layerName</strong> (<em>*</em>) – the name of the layer, set when constructing the network definition</li>
<li><strong>ms</strong> (<em>*</em>) – the time in milliseconds to execute the layer</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="consoleprofiler">
<h3>ConsoleProfiler<a class="headerlink" href="#consoleprofiler" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="tensorrt.infer.ConsoleProfiler">
<em class="property">class </em><code class="descclassname">tensorrt.infer.</code><code class="descname">ConsoleProfiler</code><a class="headerlink" href="#tensorrt.infer.ConsoleProfiler" title="Permalink to this definition">¶</a></dt>
<dd><dl class="attribute">
<dt id="tensorrt.infer.ConsoleProfiler.mProfile">
<code class="descname">mProfile</code><a class="headerlink" href="#tensorrt.infer.ConsoleProfiler.mProfile" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="tensorrt.infer.ConsoleProfiler.report_layer_time">
<code class="descname">report_layer_time</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorrt.infer.ConsoleProfiler.report_layer_time" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">reportLayerTime(const</span> <span class="pre">char</span> <span class="pre">*layerName,</span> <span class="pre">float</span> <span class="pre">ms)=0</span></code></p>
<p>layer time reporting callback</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>layerName</strong> (<em>*</em>) – the name of the layer, set when constructing the network definition</li>
<li><strong>ms</strong> (<em>*</em>) – the time in milliseconds to execute the layer</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="tensorrt.infer.ConsoleProfiler.timing_iterations">
<code class="descname">timing_iterations</code><a class="headerlink" href="#tensorrt.infer.ConsoleProfiler.timing_iterations" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="utils.html" class="btn btn-neutral float-right" title="tensorrt.utils" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../workflows/manually_construct_tensorrt_engine.html" class="btn btn-neutral" title="Manually Construct a TensorRT Engine" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, NVIDIA Corporation.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'3.0.2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>